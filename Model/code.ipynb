{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64762c3",
   "metadata": {},
   "source": [
    "# NASA Space Apps Challenge 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba9933",
   "metadata": {},
   "source": [
    "## 0.Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f8679d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5edb56",
   "metadata": {},
   "source": [
    "## 1. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b9e241a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data directory\n",
    "DATA_DIR = Path(\"./data\")\n",
    "KOI_FILE = DATA_DIR / \"Kepler Objects of Interest (KOI).csv\"\n",
    "TOI_FILE = DATA_DIR / \"TESS Objects of Interest (TOI).csv\"\n",
    "K2_FILE = DATA_DIR / \"K2 Planets and Candidates.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1b741041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kepid kepoi_name   kepler_name koi_disposition koi_pdisposition  \\\n",
       "0  10797460  K00752.01  Kepler-227 b       CONFIRMED        CANDIDATE   \n",
       "1  10797460  K00752.02  Kepler-227 c       CONFIRMED        CANDIDATE   \n",
       "2  10811496  K00753.01           NaN       CANDIDATE        CANDIDATE   \n",
       "3  10848459  K00754.01           NaN  FALSE POSITIVE   FALSE POSITIVE   \n",
       "4  10854555  K00755.01  Kepler-664 b       CONFIRMED        CANDIDATE   \n",
       "\n",
       "   koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  ...  \\\n",
       "0      1.000              0              0              0              0  ...   \n",
       "1      0.969              0              0              0              0  ...   \n",
       "2      0.000              0              0              0              0  ...   \n",
       "3      0.000              0              1              0              0  ...   \n",
       "4      1.000              0              0              0              0  ...   \n",
       "\n",
       "   koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
       "0           -81.0      4.467           0.064          -0.096     0.927   \n",
       "1           -81.0      4.467           0.064          -0.096     0.927   \n",
       "2          -176.0      4.544           0.044          -0.176     0.868   \n",
       "3          -174.0      4.564           0.053          -0.168     0.791   \n",
       "4          -211.0      4.438           0.070          -0.210     1.046   \n",
       "\n",
       "   koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "1          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "2          0.233         -0.078  297.00482  48.134129      15.436  \n",
       "3          0.201         -0.067  285.53461  48.285210      15.597  \n",
       "4          0.334         -0.133  288.75488  48.226200      15.509  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kepler Objects of Interest (KOI)\n",
    "koi = pd.read_csv(\n",
    "    KOI_FILE,\n",
    "    skiprows=range(53),   \n",
    "    header=0,\n",
    "    encoding=\"utf-8-sig\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "koi.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a150fa",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c2d2cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset\n",
    "koi_df = koi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3bdb6801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All feature columns: ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2', 'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec', 'koi_kepmag']\n",
      "Train set: (3307, 40), Validation set: (709, 40), Test set: (709, 40)\n",
      "Train labels: (3307,), Validation labels: (709,), Test labels: (709,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_koi_df(koi_df):\n",
    "    # Remove columns\n",
    "    columns_to_remove = ['kepid', 'kepoi_name', 'kepler_name', 'koi_pdisposition', 'koi_score', 'koi_teq_err1', 'koi_teq_err2']\n",
    "\n",
    "    # Remove columns\n",
    "    for c in columns_to_remove:\n",
    "        if c in koi_df.columns:\n",
    "            koi_df.drop(columns=c, inplace=True)\n",
    "    \n",
    "    # Only keep Candidate / Confirmed\n",
    "    koi_df = koi_df[koi_df['koi_disposition'].isin(['CANDIDATE', 'CONFIRMED'])]\n",
    "\n",
    "    # Binary label: Candidate=1, Confirmed=0\n",
    "    koi_df['y'] = (koi_df['koi_disposition'] == 'CANDIDATE').astype(int)\n",
    "\n",
    "    # Fill missing values\n",
    "    for col in koi_df.columns:\n",
    "        if koi_df[col].dtype in [np.float64, np.int64]:\n",
    "            koi_df[col].fillna(koi_df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            # Fill missing values with mode\n",
    "            mode = koi_df[col].mode()\n",
    "            if not mode.empty:\n",
    "                koi_df[col].fillna(mode[0], inplace=True)\n",
    "            else:\n",
    "                koi_df[col].fillna(\"missing\", inplace=True)\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = koi_df.drop(['koi_disposition', 'y'], axis=1, errors='ignore')\n",
    "    y = koi_df['y']\n",
    "\n",
    "    # Ensure all features are numeric\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "    # First split into training and temp sets (train:temp = 70%:30%)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    # Then split the temp set into validation and test sets \n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, X_scaled.columns.tolist(),scaler\n",
    "\n",
    "# Preprocess the dataset\n",
    "X_train_koi, X_val_koi, X_test_koi, y_train_koi, y_val_koi, y_test_koi, X_scaled_koi_columns, scaler_koi = preprocess_koi_df(koi_df)\n",
    "print(\"All feature columns:\", X_scaled_koi_columns)\n",
    "print(f\"Train set: {X_train_koi.shape}, Validation set: {X_val_koi.shape}, Test set: {X_test_koi.shape}\")\n",
    "print(f\"Train labels: {y_train_koi.shape}, Validation labels: {y_val_koi.shape}, Test labels: {y_test_koi.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7279e0a7",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9699c8e",
   "metadata": {},
   "source": [
    "### 3.1 LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12caec03",
   "metadata": {},
   "source": [
    "#### Base Model Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3c234478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy: 0.9988, Validation Accuracy: 0.8759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(),\n",
       " array([0, 0, 0, ..., 0, 1, 1]),\n",
       " array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1]),\n",
       " 0.998790444511642,\n",
       " 0.8758815232722144)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_lgbm_base(X_train, y_train, X_val, y_val):\n",
    "    model = lgb.LGBMClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"\\nTrain Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return model, y_train_pred, y_val_pred, train_accuracy, val_accuracy\n",
    "\n",
    "# train result\n",
    "train_lgbm_base(X_train_koi, y_train_koi, X_val_koi, y_val_koi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3932c25e",
   "metadata": {},
   "source": [
    "#### Hyper-parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4e6a8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LGBM(X_train, y_train, n_trials=40):\n",
    "    # define objective function\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"auc\",\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", -1, 12),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "            \"random_state\": 42,\n",
    "            \"verbosity\": -1,\n",
    "            \"n_estimators\": 5000,\n",
    "        }\n",
    "\n",
    "        X = np.array(X_train)\n",
    "        y = np.array(y_train)\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        pr_scores = []\n",
    "        for tr_idx, va_idx in skf.split(X, y):\n",
    "            Xtr, Xva = X[tr_idx], X[va_idx]\n",
    "            ytr, yva = y[tr_idx], y[va_idx]\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            model.fit(\n",
    "                Xtr, ytr,\n",
    "                eval_set=[(Xva, yva)],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]\n",
    "            )\n",
    "            proba = model.predict_proba(Xva)[:, 1]\n",
    "            pr_scores.append(average_precision_score(yva, proba))\n",
    "        return np.mean(pr_scores)\n",
    "\n",
    "    # create Optuna optimizer\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"lgbm_pr_auc\")\n",
    "    study.optimize(lambda t: objective(t), n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    # get best parameters\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    # train best model\n",
    "    best_model = lgb.LGBMClassifier(**best_params)\n",
    "    best_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_metric=\"aucpr\"\n",
    "    )\n",
    "\n",
    "    # output results\n",
    "    print(\"Best LGBM params:\", best_params)\n",
    "    print(\"Best CV PR-AUC:\", study.best_value)\n",
    "\n",
    "    return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "824e967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-05 14:59:43,509] A new study created in memory with name: lgbm_pr_auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LGBM model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859d74cc184a49aaa8092136adbd3127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-05 14:59:45,014] Trial 0 finished with value: 0.9255716195634708 and parameters: {'learning_rate': 0.026822456870844447, 'num_leaves': 150, 'max_depth': 2, 'min_child_samples': 51, 'subsample': 0.6161811438970609, 'colsample_bytree': 0.8831636553850064, 'reg_lambda': 0.25176630231549, 'reg_alpha': 0.07285461471510507}. Best is trial 0 with value: 0.9255716195634708.\n",
      "[I 2025-10-05 14:59:46,042] Trial 1 finished with value: 0.9235831118844988 and parameters: {'learning_rate': 0.06240840285408514, 'num_leaves': 178, 'max_depth': 7, 'min_child_samples': 60, 'subsample': 0.851823160031213, 'colsample_bytree': 0.7094729016906847, 'reg_lambda': 0.003490099675785345, 'reg_alpha': 5.1432345824839345}. Best is trial 0 with value: 0.9255716195634708.\n",
      "[I 2025-10-05 14:59:48,142] Trial 2 finished with value: 0.928078677703256 and parameters: {'learning_rate': 0.026572778953744526, 'num_leaves': 249, 'max_depth': -1, 'min_child_samples': 88, 'subsample': 0.6778401673830601, 'colsample_bytree': 0.6065107061420085, 'reg_lambda': 0.564245474418237, 'reg_alpha': 0.11649274935166065}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 14:59:49,114] Trial 3 finished with value: 0.9255530850956462 and parameters: {'learning_rate': 0.06606870234791075, 'num_leaves': 171, 'max_depth': 2, 'min_child_samples': 14, 'subsample': 0.6704164227635765, 'colsample_bytree': 0.6990975114002459, 'reg_lambda': 0.11499822889066193, 'reg_alpha': 5.313447263608461}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 14:59:58,157] Trial 4 finished with value: 0.9247587283921934 and parameters: {'learning_rate': 0.013132948854035197, 'num_leaves': 192, 'max_depth': -1, 'min_child_samples': 31, 'subsample': 0.7883922061908055, 'colsample_bytree': 0.9436872371667212, 'reg_lambda': 0.22772100931350683, 'reg_alpha': 0.003724245202391461}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:00,515] Trial 5 finished with value: 0.9250470744326741 and parameters: {'learning_rate': 0.01142712883678998, 'num_leaves': 183, 'max_depth': 3, 'min_child_samples': 60, 'subsample': 0.6532982646443661, 'colsample_bytree': 0.874948586994595, 'reg_lambda': 2.0618790924453356, 'reg_alpha': 0.0017129014565638295}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:01,720] Trial 6 finished with value: 0.9243059052824079 and parameters: {'learning_rate': 0.07635317256497773, 'num_leaves': 244, 'max_depth': 1, 'min_child_samples': 69, 'subsample': 0.8723381830657688, 'colsample_bytree': 0.7558321086416143, 'reg_lambda': 0.003178331072584761, 'reg_alpha': 0.02433543028485037}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:03,434] Trial 7 finished with value: 0.9239303673676392 and parameters: {'learning_rate': 0.036440510345862646, 'num_leaves': 140, 'max_depth': 4, 'min_child_samples': 31, 'subsample': 0.6598141708451639, 'colsample_bytree': 0.8504951116438513, 'reg_lambda': 0.7263193816397953, 'reg_alpha': 0.0018740728541694414}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:05,106] Trial 8 finished with value: 0.9261966249017538 and parameters: {'learning_rate': 0.06012709164000007, 'num_leaves': 101, 'max_depth': 9, 'min_child_samples': 79, 'subsample': 0.8432374185438516, 'colsample_bytree': 0.9611294809639764, 'reg_lambda': 0.009129497238143592, 'reg_alpha': 0.0026428148946544064}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:06,199] Trial 9 finished with value: 0.9252446159974068 and parameters: {'learning_rate': 0.09270320302318684, 'num_leaves': 213, 'max_depth': 4, 'min_child_samples': 33, 'subsample': 0.8604807548791018, 'colsample_bytree': 0.9155703865229468, 'reg_lambda': 0.0030498150801133326, 'reg_alpha': 0.3282304840388019}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:08,845] Trial 10 finished with value: 0.9265140514766632 and parameters: {'learning_rate': 0.020811713410529183, 'num_leaves': 35, 'max_depth': -1, 'min_child_samples': 98, 'subsample': 0.9996659553430495, 'colsample_bytree': 0.6140072870986656, 'reg_lambda': 6.437724519241954, 'reg_alpha': 0.4919636579810625}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:12,180] Trial 11 finished with value: 0.926642483835179 and parameters: {'learning_rate': 0.021597609656543785, 'num_leaves': 38, 'max_depth': -1, 'min_child_samples': 97, 'subsample': 0.9637451799129447, 'colsample_bytree': 0.6029548027845181, 'reg_lambda': 9.73517426927281, 'reg_alpha': 0.5683460841598341}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:15,782] Trial 12 finished with value: 0.926687818949096 and parameters: {'learning_rate': 0.018444612649770136, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 98, 'subsample': 0.7587072300613957, 'colsample_bytree': 0.6144547082194021, 'reg_lambda': 7.752710428943077, 'reg_alpha': 0.744268134844727}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:18,646] Trial 13 finished with value: 0.9261734123391404 and parameters: {'learning_rate': 0.01692772088134127, 'num_leaves': 92, 'max_depth': 10, 'min_child_samples': 83, 'subsample': 0.741562526917445, 'colsample_bytree': 0.6637091538101109, 'reg_lambda': 1.517786733751224, 'reg_alpha': 1.5811857045670166}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:20,552] Trial 14 finished with value: 0.9259987908164021 and parameters: {'learning_rate': 0.03710116097754948, 'num_leaves': 246, 'max_depth': 12, 'min_child_samples': 86, 'subsample': 0.7310177422005338, 'colsample_bytree': 0.7879072033875124, 'reg_lambda': 0.043838825287855716, 'reg_alpha': 0.054151463133514856}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:22,395] Trial 15 finished with value: 0.9276430198087475 and parameters: {'learning_rate': 0.02901882511313502, 'num_leaves': 84, 'max_depth': 6, 'min_child_samples': 91, 'subsample': 0.7321388231370352, 'colsample_bytree': 0.6565976228522077, 'reg_lambda': 2.824220145297922, 'reg_alpha': 0.015755622342650294}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:23,866] Trial 16 finished with value: 0.9265384320321521 and parameters: {'learning_rate': 0.04525282610155781, 'num_leaves': 86, 'max_depth': 6, 'min_child_samples': 75, 'subsample': 0.7042743993825192, 'colsample_bytree': 0.6785429551315939, 'reg_lambda': 0.9121774733223447, 'reg_alpha': 0.012428311321126297}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:26,404] Trial 17 finished with value: 0.9272651089653733 and parameters: {'learning_rate': 0.027912584725519295, 'num_leaves': 118, 'max_depth': 8, 'min_child_samples': 88, 'subsample': 0.6009887100430183, 'colsample_bytree': 0.749790110767667, 'reg_lambda': 2.7154942517252993, 'reg_alpha': 0.010393890190731697}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:28,486] Trial 18 finished with value: 0.9240449733007499 and parameters: {'learning_rate': 0.03989785119290864, 'num_leaves': 214, 'max_depth': 5, 'min_child_samples': 48, 'subsample': 0.7957160098121366, 'colsample_bytree': 0.6603003687286273, 'reg_lambda': 0.05166462872333031, 'reg_alpha': 0.14552858683623754}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:29,633] Trial 19 finished with value: 0.9260289699862391 and parameters: {'learning_rate': 0.04876675109335066, 'num_leaves': 63, 'max_depth': 6, 'min_child_samples': 69, 'subsample': 0.7029151484717006, 'colsample_bytree': 0.8199791293223941, 'reg_lambda': 0.3913306835798819, 'reg_alpha': 0.027325189790230332}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:32,369] Trial 20 finished with value: 0.9245220774971467 and parameters: {'learning_rate': 0.027250501016093748, 'num_leaves': 126, 'max_depth': 1, 'min_child_samples': 88, 'subsample': 0.9073938041143379, 'colsample_bytree': 0.733030860118133, 'reg_lambda': 0.019699458992431466, 'reg_alpha': 0.13363822370689837}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:34,440] Trial 21 finished with value: 0.9270826960570856 and parameters: {'learning_rate': 0.028657953921304193, 'num_leaves': 123, 'max_depth': 8, 'min_child_samples': 90, 'subsample': 0.6018406790738688, 'colsample_bytree': 0.6419780024528922, 'reg_lambda': 2.4262912174778557, 'reg_alpha': 0.009849109368026441}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:37,526] Trial 22 finished with value: 0.9254789553356852 and parameters: {'learning_rate': 0.024590905061283527, 'num_leaves': 68, 'max_depth': 10, 'min_child_samples': 71, 'subsample': 0.6329465571708077, 'colsample_bytree': 0.7667762750710239, 'reg_lambda': 4.579876559895802, 'reg_alpha': 0.007882388582659333}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:40,583] Trial 23 finished with value: 0.926584114502301 and parameters: {'learning_rate': 0.015826059344763672, 'num_leaves': 111, 'max_depth': 8, 'min_child_samples': 90, 'subsample': 0.6764504189487078, 'colsample_bytree': 0.7275989423476282, 'reg_lambda': 0.7219748458598806, 'reg_alpha': 0.028276887477420645}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:42,831] Trial 24 finished with value: 0.9266014959303591 and parameters: {'learning_rate': 0.032455226081902044, 'num_leaves': 73, 'max_depth': 7, 'min_child_samples': 80, 'subsample': 0.6989735848106248, 'colsample_bytree': 0.6361088944972062, 'reg_lambda': 3.9405031609017063, 'reg_alpha': 0.005766971880629238}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:44,932] Trial 25 finished with value: 0.9274985914757421 and parameters: {'learning_rate': 0.021345596412009674, 'num_leaves': 153, 'max_depth': 5, 'min_child_samples': 94, 'subsample': 0.6316361253889402, 'colsample_bytree': 0.6741936207194151, 'reg_lambda': 1.2395378551013092, 'reg_alpha': 0.0010813871376967302}. Best is trial 2 with value: 0.928078677703256.\n",
      "[I 2025-10-05 15:00:46,968] Trial 26 finished with value: 0.9281984622357097 and parameters: {'learning_rate': 0.02285956429919312, 'num_leaves': 222, 'max_depth': 5, 'min_child_samples': 99, 'subsample': 0.7734552603102325, 'colsample_bytree': 0.6880204590470268, 'reg_lambda': 1.2868794279031404, 'reg_alpha': 0.0011369707812822003}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:00:49,498] Trial 27 finished with value: 0.9262247663255891 and parameters: {'learning_rate': 0.013453483388372297, 'num_leaves': 224, 'max_depth': 4, 'min_child_samples': 79, 'subsample': 0.7583954072444583, 'colsample_bytree': 0.6365002108434982, 'reg_lambda': 0.3477075575121427, 'reg_alpha': 0.26154332775095773}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:00:52,330] Trial 28 finished with value: 0.92445420533067 and parameters: {'learning_rate': 0.03212502272055567, 'num_leaves': 234, 'max_depth': 1, 'min_child_samples': 100, 'subsample': 0.8187410240338595, 'colsample_bytree': 0.6925660139534593, 'reg_lambda': 0.11919373621841375, 'reg_alpha': 0.05597258295855547}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:00:55,744] Trial 29 finished with value: 0.9264678583188605 and parameters: {'learning_rate': 0.025282670119334973, 'num_leaves': 210, 'max_depth': 0, 'min_child_samples': 53, 'subsample': 0.7838068944785127, 'colsample_bytree': 0.6413899033558584, 'reg_lambda': 0.0011578377185087348, 'reg_alpha': 0.08709141952061537}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:00:57,853] Trial 30 finished with value: 0.925149970661187 and parameters: {'learning_rate': 0.01835605651066409, 'num_leaves': 253, 'max_depth': 3, 'min_child_samples': 42, 'subsample': 0.721558651173721, 'colsample_bytree': 0.8136520566754938, 'reg_lambda': 0.5017382293450477, 'reg_alpha': 1.7966264966601397}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:00:59,755] Trial 31 finished with value: 0.9261463983588545 and parameters: {'learning_rate': 0.02205097133296495, 'num_leaves': 164, 'max_depth': 5, 'min_child_samples': 93, 'subsample': 0.6297491260592732, 'colsample_bytree': 0.9961915073952725, 'reg_lambda': 1.2990584904787452, 'reg_alpha': 0.0010050080709985486}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:02,176] Trial 32 finished with value: 0.9273270587793473 and parameters: {'learning_rate': 0.023892113903055043, 'num_leaves': 149, 'max_depth': 7, 'min_child_samples': 94, 'subsample': 0.6811387060138002, 'colsample_bytree': 0.673614757463165, 'reg_lambda': 0.222734823283964, 'reg_alpha': 0.0011770666680966818}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:03,797] Trial 33 finished with value: 0.9256390653226958 and parameters: {'learning_rate': 0.019902034747892504, 'num_leaves': 195, 'max_depth': 3, 'min_child_samples': 63, 'subsample': 0.7545760803199909, 'colsample_bytree': 0.7171695208877806, 'reg_lambda': 1.206761800635351, 'reg_alpha': 0.004445610666151029}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:06,513] Trial 34 finished with value: 0.9270133333246434 and parameters: {'learning_rate': 0.01528171343683741, 'num_leaves': 156, 'max_depth': 6, 'min_child_samples': 83, 'subsample': 0.6539294896628002, 'colsample_bytree': 0.6934981770514461, 'reg_lambda': 3.6551743712825187, 'reg_alpha': 0.0027350851652839805}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:08,103] Trial 35 finished with value: 0.9270633439983207 and parameters: {'learning_rate': 0.03148228234581124, 'num_leaves': 230, 'max_depth': 2, 'min_child_samples': 11, 'subsample': 0.6318763588337819, 'colsample_bytree': 0.601213916440908, 'reg_lambda': 0.21595667335703003, 'reg_alpha': 0.018459862456554385}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:12,251] Trial 36 finished with value: 0.9265531807657574 and parameters: {'learning_rate': 0.013948252774478684, 'num_leaves': 190, 'max_depth': 5, 'min_child_samples': 22, 'subsample': 0.8238122649360415, 'colsample_bytree': 0.7058886815627463, 'reg_lambda': 0.5988064194390172, 'reg_alpha': 0.0017442677412513085}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:13,329] Trial 37 finished with value: 0.9271738609124999 and parameters: {'learning_rate': 0.045548691009608865, 'num_leaves': 138, 'max_depth': 4, 'min_child_samples': 93, 'subsample': 0.686405551286582, 'colsample_bytree': 0.6511628551957764, 'reg_lambda': 1.8886711225025707, 'reg_alpha': 0.003954138956120026}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:15,061] Trial 38 finished with value: 0.9261131669183366 and parameters: {'learning_rate': 0.023101972917173877, 'num_leaves': 201, 'max_depth': 2, 'min_child_samples': 75, 'subsample': 0.7772464072449473, 'colsample_bytree': 0.6198400516751098, 'reg_lambda': 0.14586735597882328, 'reg_alpha': 0.04531829005158813}. Best is trial 26 with value: 0.9281984622357097.\n",
      "[I 2025-10-05 15:01:18,438] Trial 39 finished with value: 0.927014097939324 and parameters: {'learning_rate': 0.010355449402143484, 'num_leaves': 255, 'max_depth': 6, 'min_child_samples': 85, 'subsample': 0.7117395904669443, 'colsample_bytree': 0.6793740953071997, 'reg_lambda': 1.0570241493903152, 'reg_alpha': 0.0022112723297694516}. Best is trial 26 with value: 0.9281984622357097.\n",
      "Best LGBM params: {'learning_rate': 0.02285956429919312, 'num_leaves': 222, 'max_depth': 5, 'min_child_samples': 99, 'subsample': 0.7734552603102325, 'colsample_bytree': 0.6880204590470268, 'reg_lambda': 1.2868794279031404, 'reg_alpha': 0.0011369707812822003}\n",
      "Best CV PR-AUC: 0.9281984622357097\n"
     ]
    }
   ],
   "source": [
    "print(\"Train LGBM model\")\n",
    "best_lgbm_model, best_lgbm_params = train_LGBM(X_train_koi, y_train_koi, n_trials=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081fb55",
   "metadata": {},
   "source": [
    "### 3.2 CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124cddb2",
   "metadata": {},
   "source": [
    "#### Base Model Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e81e6bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy: 0.9631, Validation Accuracy: 0.8815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<catboost.core.CatBoostClassifier at 0x21e75627aa0>,\n",
       " array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       " array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1], dtype=int64),\n",
       " 0.9631085576050802,\n",
       " 0.8815232722143864)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_catboost_base(X_train, y_train, X_val, y_val):\n",
    "    # initialize model\n",
    "    model = CatBoostClassifier()\n",
    "    # train model\n",
    "    model.fit(\n",
    "        Pool(X_train, y_train),\n",
    "        eval_set=Pool(X_val, y_val),\n",
    "        early_stopping_rounds=300,\n",
    "        use_best_model=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # predict\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"\\nTrain Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return model, y_train_pred, y_val_pred, train_accuracy, val_accuracy\n",
    "\n",
    "# train result\n",
    "train_catboost_base(X_train_koi, y_train_koi, X_val_koi, y_val_koi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8989e3",
   "metadata": {},
   "source": [
    "#### Hyper-parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "285c1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CatBoost(X_train, y_train, n_trials=40):\n",
    "    # define Optuna objective function\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 1e-3, 10, log=True),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
    "            \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "            \"verbose\": False,\n",
    "            \"task_type\": \"CPU\"\n",
    "        }\n",
    "        X = np.array(X_train)\n",
    "        y = np.array(y_train)\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        pr_scores = []\n",
    "        for tr_idx, va_idx in skf.split(X, y):\n",
    "            Xtr, Xva = X[tr_idx], X[va_idx]\n",
    "            ytr, yva = y[tr_idx], y[va_idx]\n",
    "            model = CatBoostClassifier(**params)\n",
    "            model.fit(\n",
    "                Pool(Xtr, ytr),\n",
    "                eval_set=Pool(Xva, yva),\n",
    "                early_stopping_rounds=200,\n",
    "                use_best_model=True,\n",
    "                verbose=False\n",
    "            )\n",
    "            proba = model.predict_proba(Xva)[:, 1]\n",
    "            pr_scores.append(average_precision_score(yva, proba))\n",
    "        return np.mean(pr_scores)\n",
    "\n",
    "    # create Optuna optimizer\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"catboost_pr_auc\")\n",
    "    study.optimize(lambda t: objective(t), n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    # get best parameters\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    # train best model\n",
    "    best_model = CatBoostClassifier(**best_params)\n",
    "    best_model.fit(\n",
    "        Pool(X_train, y_train),\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # output results\n",
    "    print(\"Best CatBoost params:\", best_params)\n",
    "    print(\"Best CV PR-AUC:\", study.best_value)\n",
    "\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b3506b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-05 15:09:59,393] A new study created in memory with name: catboost_pr_auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CatBoost model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b2db5b1be84f55903a9e7e2f8a9086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-05 15:10:07,974] Trial 0 finished with value: 0.9241000728853693 and parameters: {'iterations': 338, 'learning_rate': 0.0885388311063663, 'depth': 9, 'l2_leaf_reg': 3.5579636064925326, 'random_strength': 0.014451684810973973, 'bagging_temperature': 0.3648974108613713, 'border_count': 68}. Best is trial 0 with value: 0.9241000728853693.\n",
      "[I 2025-10-05 15:10:50,992] Trial 1 finished with value: 0.926741700868573 and parameters: {'iterations': 750, 'learning_rate': 0.006210811958201743, 'depth': 9, 'l2_leaf_reg': 3.10893668188427, 'random_strength': 0.22663599775072268, 'bagging_temperature': 0.1908569282271516, 'border_count': 190}. Best is trial 1 with value: 0.926741700868573.\n",
      "[I 2025-10-05 15:10:53,930] Trial 2 finished with value: 0.9263794618119962 and parameters: {'iterations': 107, 'learning_rate': 0.041414633469601704, 'depth': 7, 'l2_leaf_reg': 7.071567658392469, 'random_strength': 2.6013112032083616, 'bagging_temperature': 0.40922986103172465, 'border_count': 113}. Best is trial 1 with value: 0.926741700868573.\n",
      "[I 2025-10-05 15:10:56,744] Trial 3 finished with value: 0.9203595758318345 and parameters: {'iterations': 131, 'learning_rate': 0.011232631316595711, 'depth': 7, 'l2_leaf_reg': 7.63096005393262, 'random_strength': 0.023797639305644342, 'bagging_temperature': 0.5793775017511201, 'border_count': 36}. Best is trial 1 with value: 0.926741700868573.\n",
      "[I 2025-10-05 15:11:07,295] Trial 4 finished with value: 0.9174023818372736 and parameters: {'iterations': 634, 'learning_rate': 0.004009542960906039, 'depth': 4, 'l2_leaf_reg': 7.366684909741285, 'random_strength': 2.7412793310460017, 'bagging_temperature': 0.029302676655673432, 'border_count': 213}. Best is trial 1 with value: 0.926741700868573.\n",
      "[I 2025-10-05 15:11:10,153] Trial 5 finished with value: 0.9275961970734828 and parameters: {'iterations': 170, 'learning_rate': 0.12298445616105592, 'depth': 4, 'l2_leaf_reg': 8.098953989731458, 'random_strength': 1.238722331978314, 'bagging_temperature': 0.8184361067197556, 'border_count': 48}. Best is trial 5 with value: 0.9275961970734828.\n",
      "[I 2025-10-05 15:11:27,327] Trial 6 finished with value: 0.9274484539724182 and parameters: {'iterations': 910, 'learning_rate': 0.007235899384791909, 'depth': 5, 'l2_leaf_reg': 7.3618194361448595, 'random_strength': 0.252091179688316, 'bagging_temperature': 0.0032727986178833213, 'border_count': 220}. Best is trial 5 with value: 0.9275961970734828.\n",
      "[I 2025-10-05 15:11:38,530] Trial 7 finished with value: 0.9256351104394304 and parameters: {'iterations': 479, 'learning_rate': 0.0062677534338481285, 'depth': 7, 'l2_leaf_reg': 4.173309787902837, 'random_strength': 0.007850803770921497, 'bagging_temperature': 0.2551607310033883, 'border_count': 119}. Best is trial 5 with value: 0.9275961970734828.\n",
      "[I 2025-10-05 15:11:44,650] Trial 8 finished with value: 0.9293509846321479 and parameters: {'iterations': 228, 'learning_rate': 0.16718121289075413, 'depth': 7, 'l2_leaf_reg': 9.086095910594361, 'random_strength': 1.5860993384095325, 'bagging_temperature': 0.6143388609638855, 'border_count': 176}. Best is trial 8 with value: 0.9293509846321479.\n",
      "[I 2025-10-05 15:11:47,533] Trial 9 finished with value: 0.9071598721289744 and parameters: {'iterations': 128, 'learning_rate': 0.0048722949694675905, 'depth': 6, 'l2_leaf_reg': 6.780037771220592, 'random_strength': 4.278872322418169, 'bagging_temperature': 0.11575649935922994, 'border_count': 100}. Best is trial 8 with value: 0.9293509846321479.\n",
      "[I 2025-10-05 15:12:59,438] Trial 10 finished with value: 0.9132520952637929 and parameters: {'iterations': 371, 'learning_rate': 0.0010608988288137516, 'depth': 10, 'l2_leaf_reg': 9.760074535902941, 'random_strength': 0.0019833841678867084, 'bagging_temperature': 0.9687043845703673, 'border_count': 159}. Best is trial 8 with value: 0.9293509846321479.\n",
      "[I 2025-10-05 15:13:04,098] Trial 11 finished with value: 0.9311332208365604 and parameters: {'iterations': 287, 'learning_rate': 0.2626301480025373, 'depth': 4, 'l2_leaf_reg': 9.858125739947784, 'random_strength': 0.7057952345118081, 'bagging_temperature': 0.7091330560094885, 'border_count': 160}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:13:10,311] Trial 12 finished with value: 0.927833637597567 and parameters: {'iterations': 312, 'learning_rate': 0.22511574908014484, 'depth': 5, 'l2_leaf_reg': 9.973479706683515, 'random_strength': 0.6525135463372843, 'bagging_temperature': 0.6429673299664267, 'border_count': 253}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:13:19,152] Trial 13 finished with value: 0.9217423909357677 and parameters: {'iterations': 492, 'learning_rate': 0.2825281404597194, 'depth': 8, 'l2_leaf_reg': 1.0191826337098737, 'random_strength': 0.06456485512784893, 'bagging_temperature': 0.7224099590122837, 'border_count': 162}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:13:25,317] Trial 14 finished with value: 0.9270721932760528 and parameters: {'iterations': 265, 'learning_rate': 0.0365641225616133, 'depth': 6, 'l2_leaf_reg': 8.507285449058662, 'random_strength': 8.357922832831619, 'bagging_temperature': 0.8437713333790291, 'border_count': 181}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:13:31,410] Trial 15 finished with value: 0.9276636067702728 and parameters: {'iterations': 423, 'learning_rate': 0.0974351560838493, 'depth': 5, 'l2_leaf_reg': 5.575356149072811, 'random_strength': 0.6082906981378762, 'bagging_temperature': 0.4905460576245575, 'border_count': 139}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:13:49,259] Trial 16 finished with value: 0.9266410830805123 and parameters: {'iterations': 643, 'learning_rate': 0.037414291027550256, 'depth': 8, 'l2_leaf_reg': 9.18492292999759, 'random_strength': 0.14441425025111895, 'bagging_temperature': 0.715298605102544, 'border_count': 205}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:13:55,582] Trial 17 finished with value: 0.9277071914542558 and parameters: {'iterations': 245, 'learning_rate': 0.14072371533575276, 'depth': 6, 'l2_leaf_reg': 5.853176423923149, 'random_strength': 0.8289306002489502, 'bagging_temperature': 0.5335179360649039, 'border_count': 250}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:14:04,956] Trial 18 finished with value: 0.9300008169115996 and parameters: {'iterations': 559, 'learning_rate': 0.05213053432381865, 'depth': 4, 'l2_leaf_reg': 8.689161921178858, 'random_strength': 0.06044239364028866, 'bagging_temperature': 0.9775287464177576, 'border_count': 138}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:14:16,171] Trial 19 finished with value: 0.9280043572766529 and parameters: {'iterations': 608, 'learning_rate': 0.02017812519301648, 'depth': 4, 'l2_leaf_reg': 8.707951566344153, 'random_strength': 0.05582675356484996, 'bagging_temperature': 0.9943282728771898, 'border_count': 84}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:14:24,627] Trial 20 finished with value: 0.9306167334360014 and parameters: {'iterations': 807, 'learning_rate': 0.06134433059632575, 'depth': 5, 'l2_leaf_reg': 6.315980843000761, 'random_strength': 0.0031289575940334617, 'bagging_temperature': 0.8447797050297048, 'border_count': 135}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:14:32,712] Trial 21 finished with value: 0.9301851628650708 and parameters: {'iterations': 971, 'learning_rate': 0.06623672693774861, 'depth': 4, 'l2_leaf_reg': 6.204984087184731, 'random_strength': 0.0010295934941296542, 'bagging_temperature': 0.8843825000373223, 'border_count': 137}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:14:41,104] Trial 22 finished with value: 0.9303601753545898 and parameters: {'iterations': 998, 'learning_rate': 0.06750562714408477, 'depth': 5, 'l2_leaf_reg': 4.738778436824957, 'random_strength': 0.0010742002765565094, 'bagging_temperature': 0.8588308470574753, 'border_count': 122}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:14:55,319] Trial 23 finished with value: 0.9284641391630988 and parameters: {'iterations': 801, 'learning_rate': 0.02375702133256995, 'depth': 5, 'l2_leaf_reg': 4.414043148628192, 'random_strength': 0.00302665255925442, 'bagging_temperature': 0.7826404757198735, 'border_count': 109}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:02,456] Trial 24 finished with value: 0.9287434699699355 and parameters: {'iterations': 833, 'learning_rate': 0.06724199833232404, 'depth': 5, 'l2_leaf_reg': 4.946152242916659, 'random_strength': 0.005026297399504157, 'bagging_temperature': 0.8981577115077504, 'border_count': 90}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:07,678] Trial 25 finished with value: 0.9240058785128082 and parameters: {'iterations': 988, 'learning_rate': 0.19573362310362974, 'depth': 6, 'l2_leaf_reg': 2.2266017023477573, 'random_strength': 0.0010871125362643674, 'bagging_temperature': 0.7174726431796391, 'border_count': 125}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:21,182] Trial 26 finished with value: 0.9285562363658325 and parameters: {'iterations': 722, 'learning_rate': 0.014416796662249463, 'depth': 5, 'l2_leaf_reg': 5.021633184644094, 'random_strength': 0.021634922688604914, 'bagging_temperature': 0.7897702005264123, 'border_count': 158}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:32,872] Trial 27 finished with value: 0.9278280049913106 and parameters: {'iterations': 879, 'learning_rate': 0.029563219461298577, 'depth': 6, 'l2_leaf_reg': 6.466641103772937, 'random_strength': 0.0026734321371393675, 'bagging_temperature': 0.8986184221822391, 'border_count': 74}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:39,143] Trial 28 finished with value: 0.9294072983600865 and parameters: {'iterations': 922, 'learning_rate': 0.10040966122926956, 'depth': 4, 'l2_leaf_reg': 2.6496285826200308, 'random_strength': 0.00555474634822053, 'bagging_temperature': 0.6577114689229326, 'border_count': 147}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:46,016] Trial 29 finished with value: 0.9281417832363577 and parameters: {'iterations': 715, 'learning_rate': 0.07250255384168267, 'depth': 5, 'l2_leaf_reg': 3.739022196331951, 'random_strength': 0.011138786605917045, 'bagging_temperature': 0.4550918215123809, 'border_count': 65}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:50,228] Trial 30 finished with value: 0.9270057350914938 and parameters: {'iterations': 832, 'learning_rate': 0.2717794291874246, 'depth': 4, 'l2_leaf_reg': 1.7101753458164208, 'random_strength': 0.027849927035373253, 'bagging_temperature': 0.3269945260893904, 'border_count': 129}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:15:59,769] Trial 31 finished with value: 0.9298856114155163 and parameters: {'iterations': 985, 'learning_rate': 0.057909542339803735, 'depth': 4, 'l2_leaf_reg': 6.367332376744201, 'random_strength': 0.0015423348427587777, 'bagging_temperature': 0.8787856598456104, 'border_count': 150}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:16:06,523] Trial 32 finished with value: 0.9292284356314193 and parameters: {'iterations': 993, 'learning_rate': 0.10524673930371256, 'depth': 4, 'l2_leaf_reg': 5.838076428137961, 'random_strength': 0.0010149095918787945, 'bagging_temperature': 0.9112303643747125, 'border_count': 168}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:16:15,875] Trial 33 finished with value: 0.9281130031177043 and parameters: {'iterations': 923, 'learning_rate': 0.051128898211507796, 'depth': 5, 'l2_leaf_reg': 4.8531693858835725, 'random_strength': 0.0036217623894866367, 'bagging_temperature': 0.7408037424177404, 'border_count': 193}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:16:22,939] Trial 34 finished with value: 0.9296927978019733 and parameters: {'iterations': 777, 'learning_rate': 0.08053808445858159, 'depth': 4, 'l2_leaf_reg': 3.3951348644336155, 'random_strength': 0.30434386701973754, 'bagging_temperature': 0.8416167222379821, 'border_count': 104}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:16:28,357] Trial 35 finished with value: 0.9292700936531529 and parameters: {'iterations': 877, 'learning_rate': 0.1685438709721806, 'depth': 5, 'l2_leaf_reg': 6.228227744892358, 'random_strength': 0.0020152441330635266, 'bagging_temperature': 0.9356822367111421, 'border_count': 131}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:16:57,431] Trial 36 finished with value: 0.9275148326541742 and parameters: {'iterations': 953, 'learning_rate': 0.011832118557978024, 'depth': 8, 'l2_leaf_reg': 7.862177165221256, 'random_strength': 0.0014277875539407303, 'bagging_temperature': 0.7830157258563084, 'border_count': 118}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:17:13,183] Trial 37 finished with value: 0.9298708435566813 and parameters: {'iterations': 853, 'learning_rate': 0.026362298162200745, 'depth': 4, 'l2_leaf_reg': 7.1159818520693925, 'random_strength': 0.006654479611981426, 'bagging_temperature': 0.846743255237126, 'border_count': 149}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:17:21,607] Trial 38 finished with value: 0.9306465842019309 and parameters: {'iterations': 689, 'learning_rate': 0.1277787511719081, 'depth': 6, 'l2_leaf_reg': 4.1266865237346675, 'random_strength': 0.015692188117084584, 'bagging_temperature': 0.5700724756826063, 'border_count': 194}. Best is trial 11 with value: 0.9311332208365604.\n",
      "[I 2025-10-05 15:17:29,320] Trial 39 finished with value: 0.9272188222236416 and parameters: {'iterations': 702, 'learning_rate': 0.13235223108064093, 'depth': 6, 'l2_leaf_reg': 3.9845271818208223, 'random_strength': 0.013007136390213137, 'bagging_temperature': 0.6034662941598758, 'border_count': 202}. Best is trial 11 with value: 0.9311332208365604.\n",
      "Best CatBoost params: {'iterations': 287, 'learning_rate': 0.2626301480025373, 'depth': 4, 'l2_leaf_reg': 9.858125739947784, 'random_strength': 0.7057952345118081, 'bagging_temperature': 0.7091330560094885, 'border_count': 160}\n",
      "Best CV PR-AUC: 0.9311332208365604\n"
     ]
    }
   ],
   "source": [
    "print(\"Train CatBoost model\")\n",
    "best_catboost_model, best_catboost_params = train_CatBoost(X_train_koi, y_train_koi, n_trials=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219ffcf",
   "metadata": {},
   "source": [
    "### 3.3 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a4549",
   "metadata": {},
   "source": [
    "#### Base Model Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6b0f479f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy: 0.8869, Validation Accuracy: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Functional name=functional_46, built=True>,\n",
       " array([1, 0, 0, ..., 1, 1, 1]),\n",
       " array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1]),\n",
       " 0.8869065618385243,\n",
       " 0.8645980253878702)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_cnn_base_acc(X_train, y_train, X_val, y_val, seed=42, epochs=80, patience=10, batch_size=64):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    input_len = X_train.shape[1]\n",
    "    inp = keras.Input(shape=(input_len, 1))\n",
    "    x = layers.Conv1D(64, 5, padding=\"same\")(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv1D(64, 5, padding=\"same\")(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    cb = [keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\",\n",
    "                                        patience=patience, restore_best_weights=True, verbose=0)]\n",
    "\n",
    "    Xtr = X_train.values.astype(\"float32\")[..., None]\n",
    "    Xva = X_val.values.astype(\"float32\")[..., None]\n",
    "    model.fit(Xtr, y_train, validation_data=(Xva, y_val),\n",
    "              epochs=epochs, batch_size=batch_size, verbose=0, callbacks=cb)\n",
    "\n",
    "    y_train_pred = (model.predict(Xtr, verbose=0).ravel() >= 0.5).astype(int)\n",
    "    y_val_pred   = (model.predict(Xva, verbose=0).ravel() >= 0.5).astype(int)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy   = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"\\nTrain Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return model, y_train_pred, y_val_pred, train_accuracy, val_accuracy\n",
    "\n",
    "# train result\n",
    "train_cnn_base_acc(X_train_koi, y_train_koi, X_val_koi, y_val_koi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e9d746",
   "metadata": {},
   "source": [
    "#### Hyper-parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "80ff69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CNN(X_train, y_train, X_val, y_val, n_trials=40, seed=42):\n",
    "    def build_and_train_cnn(X_train, y_train, X_val, y_val, seed=42, epochs=80, patience=10, batch_size=64, target_precision=0.97, conv_filters=64, conv_kernel_size=5, dense_units=64, dropout_rate=0.3, learning_rate=1e-3):\n",
    "        tf.keras.utils.set_random_seed(seed)\n",
    "        input_len = X_train.shape[1]\n",
    "        inp = keras.Input(shape=(input_len, 1))\n",
    "        x = layers.Conv1D(conv_filters, conv_kernel_size, padding=\"same\")(inp)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.Conv1D(conv_filters, conv_kernel_size, padding=\"same\")(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(dense_units, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = keras.Model(inp, out)\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[keras.metrics.AUC(curve=\"PR\", name=\"aucpr\"), keras.metrics.AUC(curve=\"ROC\", name=\"aucroc\")]\n",
    "        )\n",
    "        cb = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_aucpr\", mode=\"max\", patience=patience, \n",
    "                restore_best_weights=True, verbose=0\n",
    "            )\n",
    "        ]\n",
    "        Xtr = X_train.values.astype(\"float32\")[..., None]\n",
    "        Xva = X_val.values.astype(\"float32\")[..., None]\n",
    "        model.fit(\n",
    "            Xtr, y_train,\n",
    "            validation_data=(Xva, y_val),\n",
    "            epochs=epochs, batch_size=batch_size, verbose=0, callbacks=cb\n",
    "        )\n",
    "        y_val_pred_prob = model.predict(Xva, verbose=0).ravel()\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_pred_prob)\n",
    "        idx = np.where(precisions >= target_precision)[0]\n",
    "        if len(idx) == 0:\n",
    "            best_thr = 0.5\n",
    "        else:\n",
    "            best_thr = thresholds[idx[0]] if idx[0] < len(thresholds) else thresholds[-1]\n",
    "        y_val_pred = (y_val_pred_prob >= best_thr).astype(int)\n",
    "        pr_auc = average_precision_score(y_val, y_val_pred_prob)\n",
    "        roc_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
    "        precision = precision_score(y_val, y_val_pred)\n",
    "        recall = recall_score(y_val, y_val_pred)\n",
    "        f1 = f1_score(y_val, y_val_pred)\n",
    "        return model, best_thr, y_val_pred, pr_auc, roc_auc, precision, recall, f1\n",
    "\n",
    "    def objective(trial):\n",
    "        conv_filters = trial.suggest_categorical(\"conv_filters\", [32, 64, 128])\n",
    "        conv_kernel_size = trial.suggest_int(\"conv_kernel_size\", 3, 7)\n",
    "        dense_units = trial.suggest_categorical(\"dense_units\", [32, 64, 128])\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "        learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "        patience = trial.suggest_int(\"patience\", 5, 15)\n",
    "        epochs = 80\n",
    "        _, _, _, pr_auc, _, _, _, _ = build_and_train_cnn(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            seed=seed, epochs=epochs, patience=patience, batch_size=batch_size,\n",
    "            target_precision=0.97,\n",
    "            conv_filters=conv_filters,\n",
    "            conv_kernel_size=conv_kernel_size,\n",
    "            dense_units=dense_units,\n",
    "            dropout_rate=dropout_rate,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "        return pr_auc\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"cnn_pr_auc\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    # Train best model\n",
    "    best_model, best_thr, y_val_pred, pr_auc, roc_auc, precision, recall, f1 = build_and_train_cnn(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        seed=seed, epochs=80, patience=best_params.get(\"patience\", 10), batch_size=best_params.get(\"batch_size\", 64),\n",
    "        target_precision=0.97,\n",
    "        conv_filters=best_params.get(\"conv_filters\", 64),\n",
    "        conv_kernel_size=best_params.get(\"conv_kernel_size\", 5),\n",
    "        dense_units=best_params.get(\"dense_units\", 64),\n",
    "        dropout_rate=best_params.get(\"dropout_rate\", 0.3),\n",
    "        learning_rate=best_params.get(\"learning_rate\", 1e-3)\n",
    "    )\n",
    "\n",
    "    print(\"Best CNN params:\", best_params)\n",
    "    print(\"Best CV PR-AUC:\", study.best_value)\n",
    "\n",
    "    return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5d92dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-05 15:40:19,094] A new study created in memory with name: cnn_pr_auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CNN model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a5b3a293f344e9a65f69d79fa946ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-05 15:40:40,348] Trial 0 finished with value: 0.8917666739115346 and parameters: {'conv_filters': 64, 'conv_kernel_size': 7, 'dense_units': 32, 'dropout_rate': 0.1358629498522655, 'learning_rate': 0.003328218531850081, 'batch_size': 128, 'patience': 7}. Best is trial 0 with value: 0.8917666739115346.\n",
      "[I 2025-10-05 15:41:25,583] Trial 1 finished with value: 0.8265625394477039 and parameters: {'conv_filters': 64, 'conv_kernel_size': 3, 'dense_units': 64, 'dropout_rate': 0.1040936701775571, 'learning_rate': 0.00023614186689174685, 'batch_size': 128, 'patience': 6}. Best is trial 0 with value: 0.8917666739115346.\n",
      "[I 2025-10-05 15:42:00,145] Trial 2 finished with value: 0.900673417694727 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.11056359958507174, 'learning_rate': 0.0012487513473011312, 'batch_size': 128, 'patience': 9}. Best is trial 2 with value: 0.900673417694727.\n",
      "[I 2025-10-05 15:42:56,388] Trial 3 finished with value: 0.8736520415370788 and parameters: {'conv_filters': 128, 'conv_kernel_size': 3, 'dense_units': 64, 'dropout_rate': 0.4092147016479888, 'learning_rate': 0.00472215837679021, 'batch_size': 128, 'patience': 7}. Best is trial 2 with value: 0.900673417694727.\n",
      "[I 2025-10-05 15:43:33,811] Trial 4 finished with value: 0.8964822442480828 and parameters: {'conv_filters': 64, 'conv_kernel_size': 4, 'dense_units': 64, 'dropout_rate': 0.297597392881925, 'learning_rate': 0.005052056940676267, 'batch_size': 128, 'patience': 15}. Best is trial 2 with value: 0.900673417694727.\n",
      "[I 2025-10-05 15:44:23,164] Trial 5 finished with value: 0.8689732313033975 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.46447184444122647, 'learning_rate': 0.00020712715924169872, 'batch_size': 128, 'patience': 5}. Best is trial 2 with value: 0.900673417694727.\n",
      "[I 2025-10-05 15:44:41,695] Trial 6 finished with value: 0.9033012656723619 and parameters: {'conv_filters': 64, 'conv_kernel_size': 6, 'dense_units': 128, 'dropout_rate': 0.38734230501117006, 'learning_rate': 0.0037482468144736684, 'batch_size': 128, 'patience': 6}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:45:02,305] Trial 7 finished with value: 0.8774341443025223 and parameters: {'conv_filters': 64, 'conv_kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.18048725647855957, 'learning_rate': 0.006342031594044177, 'batch_size': 64, 'patience': 9}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:45:21,118] Trial 8 finished with value: 0.8886679955118144 and parameters: {'conv_filters': 32, 'conv_kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.29291298668258703, 'learning_rate': 0.003393538707433713, 'batch_size': 64, 'patience': 12}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:46:01,883] Trial 9 finished with value: 0.8691078651110686 and parameters: {'conv_filters': 128, 'conv_kernel_size': 4, 'dense_units': 128, 'dropout_rate': 0.14126167492191355, 'learning_rate': 0.0006246645259243947, 'batch_size': 64, 'patience': 13}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:46:24,799] Trial 10 finished with value: 0.8711056030513397 and parameters: {'conv_filters': 32, 'conv_kernel_size': 6, 'dense_units': 128, 'dropout_rate': 0.38027512451512924, 'learning_rate': 0.0011019484855596705, 'batch_size': 32, 'patience': 11}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:46:57,932] Trial 11 finished with value: 0.8802895691741 and parameters: {'conv_filters': 128, 'conv_kernel_size': 6, 'dense_units': 128, 'dropout_rate': 0.22427438719084603, 'learning_rate': 0.0013446207539063867, 'batch_size': 32, 'patience': 9}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:47:21,581] Trial 12 finished with value: 0.8966901145690158 and parameters: {'conv_filters': 64, 'conv_kernel_size': 6, 'dense_units': 128, 'dropout_rate': 0.3750455015694176, 'learning_rate': 0.001708651661240845, 'batch_size': 128, 'patience': 8}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:47:47,193] Trial 13 finished with value: 0.8900265961773549 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.23846122413918558, 'learning_rate': 0.0006082688999967847, 'batch_size': 128, 'patience': 5}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:48:00,590] Trial 14 finished with value: 0.8627353261749068 and parameters: {'conv_filters': 32, 'conv_kernel_size': 6, 'dense_units': 128, 'dropout_rate': 0.48189214185634616, 'learning_rate': 0.0025418437066619293, 'batch_size': 128, 'patience': 10}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:48:23,362] Trial 15 finished with value: 0.8676008587012678 and parameters: {'conv_filters': 64, 'conv_kernel_size': 5, 'dense_units': 64, 'dropout_rate': 0.3334462201853707, 'learning_rate': 0.0005540301228126219, 'batch_size': 32, 'patience': 7}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:49:25,792] Trial 16 finished with value: 0.8836699601826479 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 128, 'dropout_rate': 0.4222225274806967, 'learning_rate': 0.009963983277078769, 'batch_size': 128, 'patience': 9}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:52:26,802] Trial 17 finished with value: 0.8723091603573552 and parameters: {'conv_filters': 128, 'conv_kernel_size': 6, 'dense_units': 64, 'dropout_rate': 0.24045119093956102, 'learning_rate': 0.00011158889470327058, 'batch_size': 128, 'patience': 14}. Best is trial 6 with value: 0.9033012656723619.\n",
      "[I 2025-10-05 15:53:43,252] Trial 18 finished with value: 0.905331225477777 and parameters: {'conv_filters': 64, 'conv_kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.3450353051585855, 'learning_rate': 0.0020713682041131106, 'batch_size': 64, 'patience': 11}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:54:29,465] Trial 19 finished with value: 0.8842254126638295 and parameters: {'conv_filters': 64, 'conv_kernel_size': 4, 'dense_units': 128, 'dropout_rate': 0.34114725394278517, 'learning_rate': 0.0021199097204020762, 'batch_size': 64, 'patience': 11}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:54:44,829] Trial 20 finished with value: 0.8424277504378127 and parameters: {'conv_filters': 64, 'conv_kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.4408346042522153, 'learning_rate': 0.009872234212590982, 'batch_size': 64, 'patience': 12}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:55:11,513] Trial 21 finished with value: 0.8936845606319792 and parameters: {'conv_filters': 64, 'conv_kernel_size': 6, 'dense_units': 128, 'dropout_rate': 0.3339244265197884, 'learning_rate': 0.0011782566895626677, 'batch_size': 64, 'patience': 10}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:55:33,709] Trial 22 finished with value: 0.8877134264926092 and parameters: {'conv_filters': 64, 'conv_kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.27865362618684014, 'learning_rate': 0.0007444551976038388, 'batch_size': 64, 'patience': 8}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:56:00,089] Trial 23 finished with value: 0.8932916083645065 and parameters: {'conv_filters': 32, 'conv_kernel_size': 7, 'dense_units': 32, 'dropout_rate': 0.3845873984841148, 'learning_rate': 0.0025865922576726796, 'batch_size': 32, 'patience': 11}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:56:15,432] Trial 24 finished with value: 0.8844028560727109 and parameters: {'conv_filters': 64, 'conv_kernel_size': 6, 'dense_units': 128, 'dropout_rate': 0.35409861095268363, 'learning_rate': 0.0019660278496769134, 'batch_size': 128, 'patience': 6}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:57:11,320] Trial 25 finished with value: 0.8883531548771388 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.2599403032774142, 'learning_rate': 0.00040901077561611486, 'batch_size': 64, 'patience': 10}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:57:41,456] Trial 26 finished with value: 0.8777835426617365 and parameters: {'conv_filters': 64, 'conv_kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.20528547297162256, 'learning_rate': 0.0008542985314566725, 'batch_size': 128, 'patience': 13}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:58:04,994] Trial 27 finished with value: 0.8857986575975141 and parameters: {'conv_filters': 64, 'conv_kernel_size': 4, 'dense_units': 128, 'dropout_rate': 0.4997536098164356, 'learning_rate': 0.0015484957821005046, 'batch_size': 128, 'patience': 8}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:58:14,509] Trial 28 finished with value: 0.8745401816054419 and parameters: {'conv_filters': 32, 'conv_kernel_size': 6, 'dense_units': 32, 'dropout_rate': 0.3186025665770402, 'learning_rate': 0.0037641484773130915, 'batch_size': 32, 'patience': 6}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:58:56,941] Trial 29 finished with value: 0.8970902443436592 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.1732784095152694, 'learning_rate': 0.00623747499910905, 'batch_size': 64, 'patience': 12}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 15:59:23,796] Trial 30 finished with value: 0.8859568356731344 and parameters: {'conv_filters': 64, 'conv_kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.40614453911269854, 'learning_rate': 0.0028189769006148283, 'batch_size': 128, 'patience': 9}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 16:00:08,090] Trial 31 finished with value: 0.8857644928006762 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.15389210595253228, 'learning_rate': 0.0067825592877070835, 'batch_size': 64, 'patience': 12}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 16:00:53,163] Trial 32 finished with value: 0.894218817644105 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.11959929502205192, 'learning_rate': 0.004307266296184286, 'batch_size': 64, 'patience': 13}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 16:01:27,792] Trial 33 finished with value: 0.8928807321071398 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.10812901257396075, 'learning_rate': 0.005568115888891416, 'batch_size': 64, 'patience': 11}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 16:02:13,540] Trial 34 finished with value: 0.8880202607558795 and parameters: {'conv_filters': 128, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.17266862773652114, 'learning_rate': 0.0034937351336723774, 'batch_size': 64, 'patience': 14}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 16:02:34,827] Trial 35 finished with value: 0.8625860356348197 and parameters: {'conv_filters': 128, 'conv_kernel_size': 6, 'dense_units': 64, 'dropout_rate': 0.18913416047056375, 'learning_rate': 0.007598136399056687, 'batch_size': 128, 'patience': 7}. Best is trial 18 with value: 0.905331225477777.\n",
      "[I 2025-10-05 16:02:56,953] Trial 36 finished with value: 0.9098774184957279 and parameters: {'conv_filters': 64, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.13190013091327654, 'learning_rate': 0.004976772843457371, 'batch_size': 128, 'patience': 12}. Best is trial 36 with value: 0.9098774184957279.\n",
      "[I 2025-10-05 16:03:12,208] Trial 37 finished with value: 0.8878238109344588 and parameters: {'conv_filters': 64, 'conv_kernel_size': 5, 'dense_units': 64, 'dropout_rate': 0.12625997713740963, 'learning_rate': 0.004816343276309252, 'batch_size': 128, 'patience': 5}. Best is trial 36 with value: 0.9098774184957279.\n",
      "[I 2025-10-05 16:03:32,055] Trial 38 finished with value: 0.8927212595337078 and parameters: {'conv_filters': 64, 'conv_kernel_size': 6, 'dense_units': 64, 'dropout_rate': 0.14664796667750363, 'learning_rate': 0.002137081908105083, 'batch_size': 128, 'patience': 15}. Best is trial 36 with value: 0.9098774184957279.\n",
      "[I 2025-10-05 16:03:51,787] Trial 39 finished with value: 0.8614570568193001 and parameters: {'conv_filters': 64, 'conv_kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.10358471891973894, 'learning_rate': 0.0030486553479456393, 'batch_size': 128, 'patience': 10}. Best is trial 36 with value: 0.9098774184957279.\n",
      "Best CNN params: {'conv_filters': 64, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.13190013091327654, 'learning_rate': 0.004976772843457371, 'batch_size': 128, 'patience': 12}\n",
      "Best CV PR-AUC: 0.9098774184957279\n"
     ]
    }
   ],
   "source": [
    "print(\"Train CNN model\")\n",
    "best_cnn_model, best_cnn_params = train_CNN(X_train_koi, y_train_koi, X_val_koi, y_val_koi, n_trials=40, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd177d93",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3ded5",
   "metadata": {},
   "source": [
    "### 4.1 show each models with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9c867b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM Classifer</td>\n",
       "      <td>{'learning_rate': 0.02285956429919312, 'num_leaves': 222, 'max_depth': 5, 'min_child_samples': 99, 'subsample': 0.7734552603102325, 'colsample_bytree': 0.6880204590470268, 'reg_lambda': 1.2868794279031404, 'reg_alpha': 0.0011369707812822003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost Classifer</td>\n",
       "      <td>{'iterations': 287, 'learning_rate': 0.2626301480025373, 'depth': 4, 'l2_leaf_reg': 9.858125739947784, 'random_strength': 0.7057952345118081, 'bagging_temperature': 0.7091330560094885, 'border_count': 160}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Classifer</td>\n",
       "      <td>{'conv_filters': 64, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.13190013091327654, 'learning_rate': 0.004976772843457371, 'batch_size': 128, 'patience': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  \\\n",
       "0      LGBM Classifer   \n",
       "1  CatBoost Classifer   \n",
       "2       CNN Classifer   \n",
       "\n",
       "                                                                                                                                                                                                                                     Best Parameters  \n",
       "0  {'learning_rate': 0.02285956429919312, 'num_leaves': 222, 'max_depth': 5, 'min_child_samples': 99, 'subsample': 0.7734552603102325, 'colsample_bytree': 0.6880204590470268, 'reg_lambda': 1.2868794279031404, 'reg_alpha': 0.0011369707812822003}  \n",
       "1                                      {'iterations': 287, 'learning_rate': 0.2626301480025373, 'depth': 4, 'l2_leaf_reg': 9.858125739947784, 'random_strength': 0.7057952345118081, 'bagging_temperature': 0.7091330560094885, 'border_count': 160}  \n",
       "2                                                                      {'conv_filters': 64, 'conv_kernel_size': 7, 'dense_units': 64, 'dropout_rate': 0.13190013091327654, 'learning_rate': 0.004976772843457371, 'batch_size': 128, 'patience': 12}  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show each models with best parameters\n",
    "def show_best_version():\n",
    "\n",
    "    results = {\n",
    "        'Model': [],\n",
    "        'Best Parameters': []\n",
    "    }\n",
    "\n",
    "    # LGBM\n",
    "    results['Model'].append('LGBM Classifer')\n",
    "    results['Best Parameters'].append(best_lgbm_params)\n",
    "\n",
    "    # CatBoost\n",
    "    results['Model'].append('CatBoost Classifer')\n",
    "    results['Best Parameters'].append(best_catboost_params)\n",
    "\n",
    "    # CNN\n",
    "    results['Model'].append('CNN Classifer')\n",
    "    results['Best Parameters'].append(best_cnn_params)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "results_best_version = show_best_version()\n",
    "results_best_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80e5dd",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation each models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d6dd26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8911, F1 Score: 0.8904\n",
      "Validation Accuracy: 0.8731, F1 Score: 0.8729\n",
      "Test Accuracy: 0.8519, F1 Score: 0.8506\n"
     ]
    }
   ],
   "source": [
    "# LGBM(best)\n",
    "def train_lgbm_best(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "\n",
    "    # LGBM with best parameters\n",
    "    best_lgbm = lgb.LGBMClassifier(**best_lgbm_params)\n",
    "    best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_train_pred = best_lgbm.predict(X_train)\n",
    "    y_val_pred = best_lgbm.predict(X_val)\n",
    "    y_test_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "    # accuracy\n",
    "    train_acc = accuracy_score(y_train,y_train_pred)\n",
    "    val_acc = accuracy_score(y_val,y_val_pred)\n",
    "    test_acc = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "    # F1\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    \n",
    "    # print\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    return best_lgbm,train_acc,train_f1,val_acc,val_f1,test_acc,test_f1\n",
    "\n",
    "best_lgbm,lgbm_train_acc,lgbm_train_f1,lgbm_val_acc,lgbm_val_f1,lgbm_test_acc,lgbm_test_f1 = train_lgbm_best(X_train_koi,y_train_koi,X_val_koi,y_val_koi,X_test_koi,y_test_koi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bfe4af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5438234\ttotal: 3.61ms\tremaining: 1.03s\n",
      "1:\tlearn: 0.4489417\ttotal: 7.03ms\tremaining: 1s\n",
      "2:\tlearn: 0.3976303\ttotal: 9.52ms\tremaining: 901ms\n",
      "3:\tlearn: 0.3719295\ttotal: 12.4ms\tremaining: 875ms\n",
      "4:\tlearn: 0.3551116\ttotal: 14.8ms\tremaining: 836ms\n",
      "5:\tlearn: 0.3422412\ttotal: 17.1ms\tremaining: 800ms\n",
      "6:\tlearn: 0.3324048\ttotal: 19.9ms\tremaining: 797ms\n",
      "7:\tlearn: 0.3264061\ttotal: 22.6ms\tremaining: 787ms\n",
      "8:\tlearn: 0.3198964\ttotal: 24.9ms\tremaining: 770ms\n",
      "9:\tlearn: 0.3136202\ttotal: 27.4ms\tremaining: 758ms\n",
      "10:\tlearn: 0.3087346\ttotal: 29.6ms\tremaining: 743ms\n",
      "11:\tlearn: 0.3051076\ttotal: 31.9ms\tremaining: 731ms\n",
      "12:\tlearn: 0.3025775\ttotal: 34.5ms\tremaining: 727ms\n",
      "13:\tlearn: 0.2993206\ttotal: 36.8ms\tremaining: 718ms\n",
      "14:\tlearn: 0.2970320\ttotal: 39.4ms\tremaining: 715ms\n",
      "15:\tlearn: 0.2942906\ttotal: 41.6ms\tremaining: 705ms\n",
      "16:\tlearn: 0.2917837\ttotal: 44.1ms\tremaining: 700ms\n",
      "17:\tlearn: 0.2872026\ttotal: 46.1ms\tremaining: 689ms\n",
      "18:\tlearn: 0.2849819\ttotal: 48.2ms\tremaining: 680ms\n",
      "19:\tlearn: 0.2818950\ttotal: 50.9ms\tremaining: 679ms\n",
      "20:\tlearn: 0.2802113\ttotal: 53.1ms\tremaining: 673ms\n",
      "21:\tlearn: 0.2783319\ttotal: 55.3ms\tremaining: 666ms\n",
      "22:\tlearn: 0.2779026\ttotal: 57.7ms\tremaining: 663ms\n",
      "23:\tlearn: 0.2764896\ttotal: 60.2ms\tremaining: 660ms\n",
      "24:\tlearn: 0.2744379\ttotal: 62.5ms\tremaining: 655ms\n",
      "25:\tlearn: 0.2732253\ttotal: 65.4ms\tremaining: 656ms\n",
      "26:\tlearn: 0.2703673\ttotal: 68.2ms\tremaining: 657ms\n",
      "27:\tlearn: 0.2700366\ttotal: 71ms\tremaining: 656ms\n",
      "28:\tlearn: 0.2677998\ttotal: 74.1ms\tremaining: 660ms\n",
      "29:\tlearn: 0.2656454\ttotal: 77.2ms\tremaining: 661ms\n",
      "30:\tlearn: 0.2644099\ttotal: 80.2ms\tremaining: 662ms\n",
      "31:\tlearn: 0.2617100\ttotal: 83.4ms\tremaining: 665ms\n",
      "32:\tlearn: 0.2596647\ttotal: 86.9ms\tremaining: 669ms\n",
      "33:\tlearn: 0.2575486\ttotal: 90ms\tremaining: 670ms\n",
      "34:\tlearn: 0.2542931\ttotal: 92.8ms\tremaining: 668ms\n",
      "35:\tlearn: 0.2528013\ttotal: 95.5ms\tremaining: 666ms\n",
      "36:\tlearn: 0.2511080\ttotal: 98.6ms\tremaining: 666ms\n",
      "37:\tlearn: 0.2500723\ttotal: 101ms\tremaining: 665ms\n",
      "38:\tlearn: 0.2480954\ttotal: 105ms\tremaining: 665ms\n",
      "39:\tlearn: 0.2452946\ttotal: 108ms\tremaining: 668ms\n",
      "40:\tlearn: 0.2431943\ttotal: 112ms\tremaining: 669ms\n",
      "41:\tlearn: 0.2401125\ttotal: 115ms\tremaining: 671ms\n",
      "42:\tlearn: 0.2375384\ttotal: 118ms\tremaining: 670ms\n",
      "43:\tlearn: 0.2350152\ttotal: 122ms\tremaining: 672ms\n",
      "44:\tlearn: 0.2347535\ttotal: 125ms\tremaining: 673ms\n",
      "45:\tlearn: 0.2329422\ttotal: 128ms\tremaining: 670ms\n",
      "46:\tlearn: 0.2319427\ttotal: 131ms\tremaining: 668ms\n",
      "47:\tlearn: 0.2317426\ttotal: 134ms\tremaining: 666ms\n",
      "48:\tlearn: 0.2305348\ttotal: 137ms\tremaining: 666ms\n",
      "49:\tlearn: 0.2292233\ttotal: 140ms\tremaining: 665ms\n",
      "50:\tlearn: 0.2280066\ttotal: 143ms\tremaining: 662ms\n",
      "51:\tlearn: 0.2261951\ttotal: 146ms\tremaining: 662ms\n",
      "52:\tlearn: 0.2242400\ttotal: 149ms\tremaining: 660ms\n",
      "53:\tlearn: 0.2234324\ttotal: 153ms\tremaining: 659ms\n",
      "54:\tlearn: 0.2232615\ttotal: 156ms\tremaining: 657ms\n",
      "55:\tlearn: 0.2219578\ttotal: 158ms\tremaining: 653ms\n",
      "56:\tlearn: 0.2197448\ttotal: 161ms\tremaining: 648ms\n",
      "57:\tlearn: 0.2177611\ttotal: 163ms\tremaining: 643ms\n",
      "58:\tlearn: 0.2153931\ttotal: 166ms\tremaining: 643ms\n",
      "59:\tlearn: 0.2142796\ttotal: 169ms\tremaining: 640ms\n",
      "60:\tlearn: 0.2127674\ttotal: 172ms\tremaining: 638ms\n",
      "61:\tlearn: 0.2113481\ttotal: 175ms\tremaining: 635ms\n",
      "62:\tlearn: 0.2103697\ttotal: 177ms\tremaining: 631ms\n",
      "63:\tlearn: 0.2087054\ttotal: 180ms\tremaining: 629ms\n",
      "64:\tlearn: 0.2076800\ttotal: 184ms\tremaining: 627ms\n",
      "65:\tlearn: 0.2068297\ttotal: 186ms\tremaining: 623ms\n",
      "66:\tlearn: 0.2057644\ttotal: 189ms\tremaining: 620ms\n",
      "67:\tlearn: 0.2045706\ttotal: 191ms\tremaining: 616ms\n",
      "68:\tlearn: 0.2034623\ttotal: 194ms\tremaining: 612ms\n",
      "69:\tlearn: 0.2018814\ttotal: 197ms\tremaining: 610ms\n",
      "70:\tlearn: 0.2014882\ttotal: 200ms\tremaining: 608ms\n",
      "71:\tlearn: 0.1998999\ttotal: 203ms\tremaining: 605ms\n",
      "72:\tlearn: 0.1988350\ttotal: 206ms\tremaining: 603ms\n",
      "73:\tlearn: 0.1979944\ttotal: 208ms\tremaining: 600ms\n",
      "74:\tlearn: 0.1962971\ttotal: 211ms\tremaining: 597ms\n",
      "75:\tlearn: 0.1954607\ttotal: 214ms\tremaining: 595ms\n",
      "76:\tlearn: 0.1933351\ttotal: 217ms\tremaining: 592ms\n",
      "77:\tlearn: 0.1923867\ttotal: 220ms\tremaining: 589ms\n",
      "78:\tlearn: 0.1912250\ttotal: 222ms\tremaining: 586ms\n",
      "79:\tlearn: 0.1896649\ttotal: 225ms\tremaining: 583ms\n",
      "80:\tlearn: 0.1894756\ttotal: 228ms\tremaining: 580ms\n",
      "81:\tlearn: 0.1875634\ttotal: 231ms\tremaining: 578ms\n",
      "82:\tlearn: 0.1870759\ttotal: 234ms\tremaining: 574ms\n",
      "83:\tlearn: 0.1866975\ttotal: 236ms\tremaining: 571ms\n",
      "84:\tlearn: 0.1849924\ttotal: 239ms\tremaining: 567ms\n",
      "85:\tlearn: 0.1835178\ttotal: 241ms\tremaining: 563ms\n",
      "86:\tlearn: 0.1820375\ttotal: 243ms\tremaining: 559ms\n",
      "87:\tlearn: 0.1805329\ttotal: 246ms\tremaining: 556ms\n",
      "88:\tlearn: 0.1793653\ttotal: 248ms\tremaining: 552ms\n",
      "89:\tlearn: 0.1782791\ttotal: 250ms\tremaining: 548ms\n",
      "90:\tlearn: 0.1772536\ttotal: 252ms\tremaining: 544ms\n",
      "91:\tlearn: 0.1755035\ttotal: 255ms\tremaining: 540ms\n",
      "92:\tlearn: 0.1741832\ttotal: 257ms\tremaining: 536ms\n",
      "93:\tlearn: 0.1737410\ttotal: 259ms\tremaining: 532ms\n",
      "94:\tlearn: 0.1724980\ttotal: 262ms\tremaining: 529ms\n",
      "95:\tlearn: 0.1714629\ttotal: 264ms\tremaining: 526ms\n",
      "96:\tlearn: 0.1709036\ttotal: 267ms\tremaining: 523ms\n",
      "97:\tlearn: 0.1696864\ttotal: 269ms\tremaining: 519ms\n",
      "98:\tlearn: 0.1682879\ttotal: 272ms\tremaining: 516ms\n",
      "99:\tlearn: 0.1678929\ttotal: 275ms\tremaining: 513ms\n",
      "100:\tlearn: 0.1672494\ttotal: 277ms\tremaining: 510ms\n",
      "101:\tlearn: 0.1671182\ttotal: 279ms\tremaining: 507ms\n",
      "102:\tlearn: 0.1659291\ttotal: 282ms\tremaining: 503ms\n",
      "103:\tlearn: 0.1652135\ttotal: 284ms\tremaining: 500ms\n",
      "104:\tlearn: 0.1640698\ttotal: 286ms\tremaining: 496ms\n",
      "105:\tlearn: 0.1633827\ttotal: 288ms\tremaining: 492ms\n",
      "106:\tlearn: 0.1622251\ttotal: 291ms\tremaining: 490ms\n",
      "107:\tlearn: 0.1611506\ttotal: 294ms\tremaining: 487ms\n",
      "108:\tlearn: 0.1601128\ttotal: 297ms\tremaining: 484ms\n",
      "109:\tlearn: 0.1589120\ttotal: 299ms\tremaining: 481ms\n",
      "110:\tlearn: 0.1578411\ttotal: 301ms\tremaining: 477ms\n",
      "111:\tlearn: 0.1568317\ttotal: 304ms\tremaining: 474ms\n",
      "112:\tlearn: 0.1559201\ttotal: 306ms\tremaining: 472ms\n",
      "113:\tlearn: 0.1547717\ttotal: 309ms\tremaining: 469ms\n",
      "114:\tlearn: 0.1541746\ttotal: 312ms\tremaining: 466ms\n",
      "115:\tlearn: 0.1527936\ttotal: 315ms\tremaining: 465ms\n",
      "116:\tlearn: 0.1520728\ttotal: 318ms\tremaining: 462ms\n",
      "117:\tlearn: 0.1512173\ttotal: 321ms\tremaining: 459ms\n",
      "118:\tlearn: 0.1504928\ttotal: 324ms\tremaining: 457ms\n",
      "119:\tlearn: 0.1497270\ttotal: 327ms\tremaining: 454ms\n",
      "120:\tlearn: 0.1496262\ttotal: 329ms\tremaining: 452ms\n",
      "121:\tlearn: 0.1490293\ttotal: 332ms\tremaining: 449ms\n",
      "122:\tlearn: 0.1476471\ttotal: 334ms\tremaining: 446ms\n",
      "123:\tlearn: 0.1465316\ttotal: 337ms\tremaining: 443ms\n",
      "124:\tlearn: 0.1460584\ttotal: 340ms\tremaining: 441ms\n",
      "125:\tlearn: 0.1452377\ttotal: 343ms\tremaining: 438ms\n",
      "126:\tlearn: 0.1444283\ttotal: 345ms\tremaining: 435ms\n",
      "127:\tlearn: 0.1436195\ttotal: 347ms\tremaining: 432ms\n",
      "128:\tlearn: 0.1429673\ttotal: 350ms\tremaining: 429ms\n",
      "129:\tlearn: 0.1423246\ttotal: 352ms\tremaining: 426ms\n",
      "130:\tlearn: 0.1417824\ttotal: 355ms\tremaining: 423ms\n",
      "131:\tlearn: 0.1405405\ttotal: 358ms\tremaining: 420ms\n",
      "132:\tlearn: 0.1396174\ttotal: 360ms\tremaining: 417ms\n",
      "133:\tlearn: 0.1391758\ttotal: 362ms\tremaining: 414ms\n",
      "134:\tlearn: 0.1384215\ttotal: 365ms\tremaining: 411ms\n",
      "135:\tlearn: 0.1379100\ttotal: 367ms\tremaining: 407ms\n",
      "136:\tlearn: 0.1367302\ttotal: 369ms\tremaining: 404ms\n",
      "137:\tlearn: 0.1363977\ttotal: 371ms\tremaining: 401ms\n",
      "138:\tlearn: 0.1356824\ttotal: 374ms\tremaining: 398ms\n",
      "139:\tlearn: 0.1344832\ttotal: 376ms\tremaining: 394ms\n",
      "140:\tlearn: 0.1335485\ttotal: 378ms\tremaining: 391ms\n",
      "141:\tlearn: 0.1329128\ttotal: 380ms\tremaining: 388ms\n",
      "142:\tlearn: 0.1315831\ttotal: 382ms\tremaining: 385ms\n",
      "143:\tlearn: 0.1307571\ttotal: 384ms\tremaining: 382ms\n",
      "144:\tlearn: 0.1303417\ttotal: 387ms\tremaining: 379ms\n",
      "145:\tlearn: 0.1300640\ttotal: 389ms\tremaining: 376ms\n",
      "146:\tlearn: 0.1287115\ttotal: 392ms\tremaining: 373ms\n",
      "147:\tlearn: 0.1280405\ttotal: 395ms\tremaining: 371ms\n",
      "148:\tlearn: 0.1275269\ttotal: 397ms\tremaining: 368ms\n",
      "149:\tlearn: 0.1265636\ttotal: 399ms\tremaining: 365ms\n",
      "150:\tlearn: 0.1262499\ttotal: 402ms\tremaining: 362ms\n",
      "151:\tlearn: 0.1260889\ttotal: 404ms\tremaining: 359ms\n",
      "152:\tlearn: 0.1258271\ttotal: 407ms\tremaining: 356ms\n",
      "153:\tlearn: 0.1255824\ttotal: 409ms\tremaining: 354ms\n",
      "154:\tlearn: 0.1246892\ttotal: 412ms\tremaining: 351ms\n",
      "155:\tlearn: 0.1235975\ttotal: 415ms\tremaining: 348ms\n",
      "156:\tlearn: 0.1230796\ttotal: 417ms\tremaining: 345ms\n",
      "157:\tlearn: 0.1222051\ttotal: 420ms\tremaining: 343ms\n",
      "158:\tlearn: 0.1215111\ttotal: 423ms\tremaining: 341ms\n",
      "159:\tlearn: 0.1214570\ttotal: 426ms\tremaining: 338ms\n",
      "160:\tlearn: 0.1207790\ttotal: 429ms\tremaining: 336ms\n",
      "161:\tlearn: 0.1204429\ttotal: 431ms\tremaining: 333ms\n",
      "162:\tlearn: 0.1194232\ttotal: 434ms\tremaining: 330ms\n",
      "163:\tlearn: 0.1186790\ttotal: 436ms\tremaining: 327ms\n",
      "164:\tlearn: 0.1182837\ttotal: 439ms\tremaining: 325ms\n",
      "165:\tlearn: 0.1176212\ttotal: 442ms\tremaining: 322ms\n",
      "166:\tlearn: 0.1171264\ttotal: 445ms\tremaining: 319ms\n",
      "167:\tlearn: 0.1165467\ttotal: 447ms\tremaining: 317ms\n",
      "168:\tlearn: 0.1160610\ttotal: 450ms\tremaining: 314ms\n",
      "169:\tlearn: 0.1153664\ttotal: 452ms\tremaining: 311ms\n",
      "170:\tlearn: 0.1143325\ttotal: 455ms\tremaining: 309ms\n",
      "171:\tlearn: 0.1134993\ttotal: 458ms\tremaining: 306ms\n",
      "172:\tlearn: 0.1127340\ttotal: 460ms\tremaining: 303ms\n",
      "173:\tlearn: 0.1118392\ttotal: 462ms\tremaining: 300ms\n",
      "174:\tlearn: 0.1113536\ttotal: 464ms\tremaining: 297ms\n",
      "175:\tlearn: 0.1110929\ttotal: 467ms\tremaining: 294ms\n",
      "176:\tlearn: 0.1107100\ttotal: 469ms\tremaining: 292ms\n",
      "177:\tlearn: 0.1102136\ttotal: 471ms\tremaining: 289ms\n",
      "178:\tlearn: 0.1100905\ttotal: 474ms\tremaining: 286ms\n",
      "179:\tlearn: 0.1098866\ttotal: 476ms\tremaining: 283ms\n",
      "180:\tlearn: 0.1096229\ttotal: 479ms\tremaining: 280ms\n",
      "181:\tlearn: 0.1090678\ttotal: 481ms\tremaining: 277ms\n",
      "182:\tlearn: 0.1083435\ttotal: 483ms\tremaining: 275ms\n",
      "183:\tlearn: 0.1078559\ttotal: 486ms\tremaining: 272ms\n",
      "184:\tlearn: 0.1069679\ttotal: 488ms\tremaining: 269ms\n",
      "185:\tlearn: 0.1063216\ttotal: 490ms\tremaining: 266ms\n",
      "186:\tlearn: 0.1053362\ttotal: 493ms\tremaining: 263ms\n",
      "187:\tlearn: 0.1051730\ttotal: 495ms\tremaining: 260ms\n",
      "188:\tlearn: 0.1048917\ttotal: 497ms\tremaining: 258ms\n",
      "189:\tlearn: 0.1044562\ttotal: 499ms\tremaining: 255ms\n",
      "190:\tlearn: 0.1040561\ttotal: 501ms\tremaining: 252ms\n",
      "191:\tlearn: 0.1039411\ttotal: 504ms\tremaining: 249ms\n",
      "192:\tlearn: 0.1034050\ttotal: 506ms\tremaining: 247ms\n",
      "193:\tlearn: 0.1027213\ttotal: 509ms\tremaining: 244ms\n",
      "194:\tlearn: 0.1024631\ttotal: 512ms\tremaining: 242ms\n",
      "195:\tlearn: 0.1020975\ttotal: 515ms\tremaining: 239ms\n",
      "196:\tlearn: 0.1018831\ttotal: 518ms\tremaining: 237ms\n",
      "197:\tlearn: 0.1013845\ttotal: 521ms\tremaining: 234ms\n",
      "198:\tlearn: 0.1010333\ttotal: 524ms\tremaining: 232ms\n",
      "199:\tlearn: 0.1005882\ttotal: 527ms\tremaining: 229ms\n",
      "200:\tlearn: 0.1005148\ttotal: 529ms\tremaining: 226ms\n",
      "201:\tlearn: 0.0997074\ttotal: 531ms\tremaining: 223ms\n",
      "202:\tlearn: 0.0990135\ttotal: 533ms\tremaining: 221ms\n",
      "203:\tlearn: 0.0984070\ttotal: 536ms\tremaining: 218ms\n",
      "204:\tlearn: 0.0979235\ttotal: 538ms\tremaining: 215ms\n",
      "205:\tlearn: 0.0975020\ttotal: 540ms\tremaining: 212ms\n",
      "206:\tlearn: 0.0969513\ttotal: 542ms\tremaining: 210ms\n",
      "207:\tlearn: 0.0967075\ttotal: 544ms\tremaining: 207ms\n",
      "208:\tlearn: 0.0962438\ttotal: 546ms\tremaining: 204ms\n",
      "209:\tlearn: 0.0957543\ttotal: 549ms\tremaining: 201ms\n",
      "210:\tlearn: 0.0953530\ttotal: 552ms\tremaining: 199ms\n",
      "211:\tlearn: 0.0946990\ttotal: 554ms\tremaining: 196ms\n",
      "212:\tlearn: 0.0945299\ttotal: 556ms\tremaining: 193ms\n",
      "213:\tlearn: 0.0944499\ttotal: 558ms\tremaining: 190ms\n",
      "214:\tlearn: 0.0942041\ttotal: 561ms\tremaining: 188ms\n",
      "215:\tlearn: 0.0933668\ttotal: 563ms\tremaining: 185ms\n",
      "216:\tlearn: 0.0929984\ttotal: 565ms\tremaining: 182ms\n",
      "217:\tlearn: 0.0926656\ttotal: 567ms\tremaining: 180ms\n",
      "218:\tlearn: 0.0919911\ttotal: 569ms\tremaining: 177ms\n",
      "219:\tlearn: 0.0916887\ttotal: 571ms\tremaining: 174ms\n",
      "220:\tlearn: 0.0913128\ttotal: 574ms\tremaining: 171ms\n",
      "221:\tlearn: 0.0912106\ttotal: 576ms\tremaining: 169ms\n",
      "222:\tlearn: 0.0904133\ttotal: 578ms\tremaining: 166ms\n",
      "223:\tlearn: 0.0902843\ttotal: 580ms\tremaining: 163ms\n",
      "224:\tlearn: 0.0896972\ttotal: 583ms\tremaining: 161ms\n",
      "225:\tlearn: 0.0891414\ttotal: 585ms\tremaining: 158ms\n",
      "226:\tlearn: 0.0886349\ttotal: 588ms\tremaining: 155ms\n",
      "227:\tlearn: 0.0883427\ttotal: 590ms\tremaining: 153ms\n",
      "228:\tlearn: 0.0881270\ttotal: 594ms\tremaining: 150ms\n",
      "229:\tlearn: 0.0873929\ttotal: 597ms\tremaining: 148ms\n",
      "230:\tlearn: 0.0867886\ttotal: 600ms\tremaining: 146ms\n",
      "231:\tlearn: 0.0865796\ttotal: 604ms\tremaining: 143ms\n",
      "232:\tlearn: 0.0861856\ttotal: 606ms\tremaining: 140ms\n",
      "233:\tlearn: 0.0860777\ttotal: 609ms\tremaining: 138ms\n",
      "234:\tlearn: 0.0856380\ttotal: 611ms\tremaining: 135ms\n",
      "235:\tlearn: 0.0851278\ttotal: 614ms\tremaining: 133ms\n",
      "236:\tlearn: 0.0845420\ttotal: 617ms\tremaining: 130ms\n",
      "237:\tlearn: 0.0840086\ttotal: 620ms\tremaining: 128ms\n",
      "238:\tlearn: 0.0836783\ttotal: 622ms\tremaining: 125ms\n",
      "239:\tlearn: 0.0833016\ttotal: 625ms\tremaining: 122ms\n",
      "240:\tlearn: 0.0827684\ttotal: 628ms\tremaining: 120ms\n",
      "241:\tlearn: 0.0822957\ttotal: 631ms\tremaining: 117ms\n",
      "242:\tlearn: 0.0819267\ttotal: 633ms\tremaining: 115ms\n",
      "243:\tlearn: 0.0815895\ttotal: 636ms\tremaining: 112ms\n",
      "244:\tlearn: 0.0810677\ttotal: 638ms\tremaining: 109ms\n",
      "245:\tlearn: 0.0805466\ttotal: 640ms\tremaining: 107ms\n",
      "246:\tlearn: 0.0803642\ttotal: 643ms\tremaining: 104ms\n",
      "247:\tlearn: 0.0800870\ttotal: 646ms\tremaining: 102ms\n",
      "248:\tlearn: 0.0794893\ttotal: 648ms\tremaining: 99ms\n",
      "249:\tlearn: 0.0792471\ttotal: 651ms\tremaining: 96.4ms\n",
      "250:\tlearn: 0.0792192\ttotal: 654ms\tremaining: 93.8ms\n",
      "251:\tlearn: 0.0787408\ttotal: 657ms\tremaining: 91.2ms\n",
      "252:\tlearn: 0.0785494\ttotal: 659ms\tremaining: 88.6ms\n",
      "253:\tlearn: 0.0783914\ttotal: 662ms\tremaining: 86ms\n",
      "254:\tlearn: 0.0779681\ttotal: 665ms\tremaining: 83.4ms\n",
      "255:\tlearn: 0.0776613\ttotal: 667ms\tremaining: 80.8ms\n",
      "256:\tlearn: 0.0773809\ttotal: 669ms\tremaining: 78.1ms\n",
      "257:\tlearn: 0.0771712\ttotal: 671ms\tremaining: 75.5ms\n",
      "258:\tlearn: 0.0768738\ttotal: 674ms\tremaining: 72.8ms\n",
      "259:\tlearn: 0.0762334\ttotal: 676ms\tremaining: 70.2ms\n",
      "260:\tlearn: 0.0759132\ttotal: 678ms\tremaining: 67.6ms\n",
      "261:\tlearn: 0.0753329\ttotal: 681ms\tremaining: 65ms\n",
      "262:\tlearn: 0.0751849\ttotal: 683ms\tremaining: 62.4ms\n",
      "263:\tlearn: 0.0749642\ttotal: 686ms\tremaining: 59.7ms\n",
      "264:\tlearn: 0.0748469\ttotal: 688ms\tremaining: 57.1ms\n",
      "265:\tlearn: 0.0744926\ttotal: 690ms\tremaining: 54.5ms\n",
      "266:\tlearn: 0.0741167\ttotal: 693ms\tremaining: 51.9ms\n",
      "267:\tlearn: 0.0735633\ttotal: 695ms\tremaining: 49.3ms\n",
      "268:\tlearn: 0.0733733\ttotal: 697ms\tremaining: 46.7ms\n",
      "269:\tlearn: 0.0729637\ttotal: 700ms\tremaining: 44.1ms\n",
      "270:\tlearn: 0.0725461\ttotal: 702ms\tremaining: 41.4ms\n",
      "271:\tlearn: 0.0719559\ttotal: 704ms\tremaining: 38.8ms\n",
      "272:\tlearn: 0.0716603\ttotal: 706ms\tremaining: 36.2ms\n",
      "273:\tlearn: 0.0714195\ttotal: 709ms\tremaining: 33.6ms\n",
      "274:\tlearn: 0.0709534\ttotal: 712ms\tremaining: 31.1ms\n",
      "275:\tlearn: 0.0705621\ttotal: 715ms\tremaining: 28.5ms\n",
      "276:\tlearn: 0.0701189\ttotal: 717ms\tremaining: 25.9ms\n",
      "277:\tlearn: 0.0696632\ttotal: 719ms\tremaining: 23.3ms\n",
      "278:\tlearn: 0.0693334\ttotal: 722ms\tremaining: 20.7ms\n",
      "279:\tlearn: 0.0689864\ttotal: 724ms\tremaining: 18.1ms\n",
      "280:\tlearn: 0.0684884\ttotal: 727ms\tremaining: 15.5ms\n",
      "281:\tlearn: 0.0681858\ttotal: 729ms\tremaining: 12.9ms\n",
      "282:\tlearn: 0.0681504\ttotal: 731ms\tremaining: 10.3ms\n",
      "283:\tlearn: 0.0679930\ttotal: 733ms\tremaining: 7.74ms\n",
      "284:\tlearn: 0.0675748\ttotal: 735ms\tremaining: 5.16ms\n",
      "285:\tlearn: 0.0671349\ttotal: 737ms\tremaining: 2.58ms\n",
      "286:\tlearn: 0.0664195\ttotal: 740ms\tremaining: 0us\n",
      "Train Accuracy: 0.9897, F1 Score: 0.9897\n",
      "Validation Accuracy: 0.8815, F1 Score: 0.8817\n",
      "Test Accuracy: 0.8632, F1 Score: 0.8622\n"
     ]
    }
   ],
   "source": [
    "# CatBoost(best)\n",
    "def train_catboost_best(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # CatBoost with best parameters\n",
    "    best_catboost = CatBoostClassifier(**best_catboost_params)\n",
    "    best_catboost.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_train_pred = best_catboost.predict(X_train)\n",
    "    y_val_pred = best_catboost.predict(X_val)\n",
    "    y_test_pred = best_catboost.predict(X_test)\n",
    "\n",
    "    # accuracy\n",
    "    train_acc = accuracy_score(y_train,y_train_pred)\n",
    "    val_acc = accuracy_score(y_val,y_val_pred)\n",
    "    test_acc = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "    # F1\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # print\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    return best_catboost,train_acc,train_f1,val_acc,val_f1,test_acc,test_f1\n",
    "\n",
    "best_catboost,catboost_train_acc,catboost_train_f1,catboost_val_acc,catboost_val_f1,catboost_test_acc,catboost_test_f1 = train_catboost_best(X_train_koi,y_train_koi,X_val_koi,y_val_koi,X_test_koi,y_test_koi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "94300d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Train Accuracy: 0.8981, F1 Score: 0.8986\n",
      "Validation Accuracy: 0.8392, F1 Score: 0.8402\n",
      "Test Accuracy: 0.8575, F1 Score: 0.8581\n"
     ]
    }
   ],
   "source": [
    "# CNN(best)\n",
    "def train_cnn_best(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    cnn_params = best_cnn_params.copy()\n",
    "    batch_size = cnn_params.pop(\"batch_size\", 64)\n",
    "    patience = cnn_params.pop(\"patience\", 10)\n",
    "\n",
    "    # build CNN model\n",
    "    def build_cnn(input_len, conv_filters=64, conv_kernel_size=5, dense_units=64,\n",
    "                  dropout_rate=0.3, learning_rate=1e-3, seed=42):\n",
    "        tf.keras.utils.set_random_seed(seed)\n",
    "        inp = keras.Input(shape=(input_len, 1))\n",
    "        x = layers.Conv1D(conv_filters, conv_kernel_size, padding=\"same\")(inp)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.Conv1D(conv_filters, conv_kernel_size, padding=\"same\")(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(dense_units, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = keras.Model(inp, out)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                      loss=\"binary_crossentropy\",\n",
    "                      metrics=[keras.metrics.AUC(curve=\"PR\", name=\"aucpr\")])\n",
    "        return model\n",
    "\n",
    "    # build model\n",
    "    model_cnn = build_cnn(X_train.shape[1], **cnn_params)\n",
    "    cb = [keras.callbacks.EarlyStopping(monitor=\"val_aucpr\", mode=\"max\",\n",
    "                                        patience=patience, restore_best_weights=True, verbose=0)]\n",
    "    # train model\n",
    "    model_cnn.fit(\n",
    "        X_train.values.astype(\"float32\")[..., None], y_train,\n",
    "        validation_data=(X_val.values.astype(\"float32\")[..., None], y_val),\n",
    "        epochs=80, batch_size=batch_size, verbose=0, callbacks=cb\n",
    "    )\n",
    "\n",
    "    # predict probability\n",
    "    y_train_pred_prob = model_cnn.predict(X_train.values.astype(\"float32\")[..., None])\n",
    "    y_val_pred_prob = model_cnn.predict(X_val.values.astype(\"float32\")[..., None])\n",
    "    y_test_pred_prob = model_cnn.predict(X_test.values.astype(\"float32\")[..., None])\n",
    "\n",
    "    # probability to class (0.5 as threshold)\n",
    "    y_train_pred = (y_train_pred_prob > 0.5).astype(int).flatten()\n",
    "    y_val_pred = (y_val_pred_prob > 0.5).astype(int).flatten()\n",
    "    y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "    # calculate accuracy\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # calculate F1 score\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    # print result\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    return model_cnn, train_acc, train_f1, val_acc, val_f1, test_acc, test_f1\n",
    "\n",
    "best_cnn, cnn_train_acc, cnn_train_f1, cnn_val_acc, cnn_val_f1, cnn_test_acc, cnn_test_f1 = train_cnn_best(X_train_koi, y_train_koi, X_val_koi, y_val_koi, X_test_koi, y_test_koi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ac0a107b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1 Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM Classifer</td>\n",
       "      <td>0.891140</td>\n",
       "      <td>0.890371</td>\n",
       "      <td>0.873061</td>\n",
       "      <td>0.872937</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.850621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost Classifer</td>\n",
       "      <td>0.989719</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.881523</td>\n",
       "      <td>0.881730</td>\n",
       "      <td>0.863188</td>\n",
       "      <td>0.862196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Classifer</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.898593</td>\n",
       "      <td>0.839210</td>\n",
       "      <td>0.840201</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.858115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Train Accuracy  Train F1 Score  Validation Accuracy  \\\n",
       "0      LGBM Classifer        0.891140        0.890371             0.873061   \n",
       "1  CatBoost Classifer        0.989719        0.989712             0.881523   \n",
       "2       CNN Classifer        0.898095        0.898593             0.839210   \n",
       "\n",
       "   Validation F1 Score  Test Accuracy  Test F1 Score  \n",
       "0             0.872937       0.851904       0.850621  \n",
       "1             0.881730       0.863188       0.862196  \n",
       "2             0.840201       0.857546       0.858115  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show each models' accuracy and f1 score on the train,validation and test data sets\n",
    "def evaluation_acc():\n",
    "    results = {\n",
    "        'Model': [],\n",
    "        'Train Accuracy': [],\n",
    "        'Train F1 Score': [],\n",
    "        'Validation Accuracy': [],\n",
    "        'Validation F1 Score': [],\n",
    "        'Test Accuracy': [],\n",
    "        'Test F1 Score': []\n",
    "    }\n",
    "\n",
    "    # LGBM\n",
    "    results['Model'].append('LGBM Classifer')\n",
    "    results['Train Accuracy'].append(lgbm_train_acc)\n",
    "    results['Train F1 Score'].append(lgbm_train_f1)\n",
    "    results['Validation Accuracy'].append(lgbm_val_acc)\n",
    "    results['Validation F1 Score'].append(lgbm_val_f1)\n",
    "    results['Test Accuracy'].append(lgbm_test_acc)\n",
    "    results['Test F1 Score'].append(lgbm_test_f1)\n",
    "\n",
    "    # CatBoost\n",
    "    results['Model'].append('CatBoost Classifer')\n",
    "    results['Train Accuracy'].append(catboost_train_acc)\n",
    "    results['Train F1 Score'].append(catboost_train_f1)\n",
    "    results['Validation Accuracy'].append(catboost_val_acc)\n",
    "    results['Validation F1 Score'].append(catboost_val_f1)\n",
    "    results['Test Accuracy'].append(catboost_test_acc)\n",
    "    results['Test F1 Score'].append(catboost_test_f1)\n",
    "\n",
    "    # CNN\n",
    "    results['Model'].append('CNN Classifer')\n",
    "    results['Train Accuracy'].append(cnn_train_acc)\n",
    "    results['Train F1 Score'].append(cnn_train_f1)\n",
    "    results['Validation Accuracy'].append(cnn_val_acc)\n",
    "    results['Validation F1 Score'].append(cnn_val_f1)\n",
    "    results['Test Accuracy'].append(cnn_test_acc)\n",
    "    results['Test F1 Score'].append(cnn_test_f1)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "results_acc = evaluation_acc()\n",
    "results_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d40fcb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a bar chart for each indicator\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metrics = ['Train Accuracy', 'Train F1 Score', 'Validation Accuracy', 'Validation F1 Score', 'Test Accuracy', 'Test F1 Score']\n",
    "results_acc.plot(x='Model', y=metrics, kind='bar', ax=ax)\n",
    "\n",
    "# Set title and tags\n",
    "plt.title('Classifier Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Show bar Chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc717704",
   "metadata": {},
   "source": [
    "## 5. The Best Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "76f89151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    #catboost with best parameters\n",
    "    best_catboost = CatBoostClassifier(**best_catboost_params)\n",
    "    best_catboost.fit(x_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_train_pred = best_catboost.predict(x_train)\n",
    "    y_val_pred = best_catboost.predict(x_val)\n",
    "    y_test_pred = best_catboost.predict(x_test)\n",
    "\n",
    "    # accuracy\n",
    "    train_acc = accuracy_score(y_train,y_train_pred)\n",
    "    val_acc = accuracy_score(y_val,y_val_pred)\n",
    "    test_acc = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "    # Calculate the precision, recall, and F1 score on the train set\n",
    "    train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "    # Calculate the precision, recall, and F1 score on the validation set\n",
    "    val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "    # Calculate the precision, recall, and F1 score on the test set\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # print\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    return  best_catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ff63f2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5438234\ttotal: 3.07ms\tremaining: 879ms\n",
      "1:\tlearn: 0.4489417\ttotal: 6.12ms\tremaining: 871ms\n",
      "2:\tlearn: 0.3976303\ttotal: 8.07ms\tremaining: 764ms\n",
      "3:\tlearn: 0.3719295\ttotal: 10.3ms\tremaining: 729ms\n",
      "4:\tlearn: 0.3551116\ttotal: 12.7ms\tremaining: 714ms\n",
      "5:\tlearn: 0.3422412\ttotal: 14.7ms\tremaining: 690ms\n",
      "6:\tlearn: 0.3324048\ttotal: 17.1ms\tremaining: 685ms\n",
      "7:\tlearn: 0.3264061\ttotal: 19.8ms\tremaining: 690ms\n",
      "8:\tlearn: 0.3198964\ttotal: 22ms\tremaining: 679ms\n",
      "9:\tlearn: 0.3136202\ttotal: 24.1ms\tremaining: 668ms\n",
      "10:\tlearn: 0.3087346\ttotal: 26.5ms\tremaining: 665ms\n",
      "11:\tlearn: 0.3051076\ttotal: 29.3ms\tremaining: 671ms\n",
      "12:\tlearn: 0.3025775\ttotal: 31.5ms\tremaining: 663ms\n",
      "13:\tlearn: 0.2993206\ttotal: 33.9ms\tremaining: 661ms\n",
      "14:\tlearn: 0.2970320\ttotal: 36ms\tremaining: 652ms\n",
      "15:\tlearn: 0.2942906\ttotal: 38.7ms\tremaining: 655ms\n",
      "16:\tlearn: 0.2917837\ttotal: 41.2ms\tremaining: 654ms\n",
      "17:\tlearn: 0.2872026\ttotal: 43.7ms\tremaining: 653ms\n",
      "18:\tlearn: 0.2849819\ttotal: 46.2ms\tremaining: 651ms\n",
      "19:\tlearn: 0.2818950\ttotal: 48.6ms\tremaining: 649ms\n",
      "20:\tlearn: 0.2802113\ttotal: 50.7ms\tremaining: 643ms\n",
      "21:\tlearn: 0.2783319\ttotal: 53ms\tremaining: 638ms\n",
      "22:\tlearn: 0.2779026\ttotal: 55.3ms\tremaining: 635ms\n",
      "23:\tlearn: 0.2764896\ttotal: 57.5ms\tremaining: 630ms\n",
      "24:\tlearn: 0.2744379\ttotal: 60ms\tremaining: 629ms\n",
      "25:\tlearn: 0.2732253\ttotal: 62ms\tremaining: 623ms\n",
      "26:\tlearn: 0.2703673\ttotal: 64.8ms\tremaining: 624ms\n",
      "27:\tlearn: 0.2700366\ttotal: 67.8ms\tremaining: 627ms\n",
      "28:\tlearn: 0.2677998\ttotal: 70.5ms\tremaining: 627ms\n",
      "29:\tlearn: 0.2656454\ttotal: 73.3ms\tremaining: 628ms\n",
      "30:\tlearn: 0.2644099\ttotal: 76.1ms\tremaining: 628ms\n",
      "31:\tlearn: 0.2617100\ttotal: 78.7ms\tremaining: 627ms\n",
      "32:\tlearn: 0.2596647\ttotal: 81.3ms\tremaining: 626ms\n",
      "33:\tlearn: 0.2575486\ttotal: 83.7ms\tremaining: 623ms\n",
      "34:\tlearn: 0.2542931\ttotal: 86.7ms\tremaining: 624ms\n",
      "35:\tlearn: 0.2528013\ttotal: 89.1ms\tremaining: 621ms\n",
      "36:\tlearn: 0.2511080\ttotal: 91.6ms\tremaining: 619ms\n",
      "37:\tlearn: 0.2500723\ttotal: 94.4ms\tremaining: 619ms\n",
      "38:\tlearn: 0.2480954\ttotal: 97ms\tremaining: 617ms\n",
      "39:\tlearn: 0.2452946\ttotal: 99.5ms\tremaining: 614ms\n",
      "40:\tlearn: 0.2431943\ttotal: 102ms\tremaining: 613ms\n",
      "41:\tlearn: 0.2401125\ttotal: 105ms\tremaining: 613ms\n",
      "42:\tlearn: 0.2375384\ttotal: 109ms\tremaining: 616ms\n",
      "43:\tlearn: 0.2350152\ttotal: 112ms\tremaining: 619ms\n",
      "44:\tlearn: 0.2347535\ttotal: 115ms\tremaining: 619ms\n",
      "45:\tlearn: 0.2329422\ttotal: 118ms\tremaining: 616ms\n",
      "46:\tlearn: 0.2319427\ttotal: 120ms\tremaining: 615ms\n",
      "47:\tlearn: 0.2317426\ttotal: 123ms\tremaining: 613ms\n",
      "48:\tlearn: 0.2305348\ttotal: 126ms\tremaining: 612ms\n",
      "49:\tlearn: 0.2292233\ttotal: 129ms\tremaining: 611ms\n",
      "50:\tlearn: 0.2280066\ttotal: 132ms\tremaining: 609ms\n",
      "51:\tlearn: 0.2261951\ttotal: 135ms\tremaining: 608ms\n",
      "52:\tlearn: 0.2242400\ttotal: 137ms\tremaining: 607ms\n",
      "53:\tlearn: 0.2234324\ttotal: 140ms\tremaining: 605ms\n",
      "54:\tlearn: 0.2232615\ttotal: 143ms\tremaining: 603ms\n",
      "55:\tlearn: 0.2219578\ttotal: 146ms\tremaining: 602ms\n",
      "56:\tlearn: 0.2197448\ttotal: 149ms\tremaining: 599ms\n",
      "57:\tlearn: 0.2177611\ttotal: 152ms\tremaining: 599ms\n",
      "58:\tlearn: 0.2153931\ttotal: 155ms\tremaining: 597ms\n",
      "59:\tlearn: 0.2142796\ttotal: 158ms\tremaining: 596ms\n",
      "60:\tlearn: 0.2127674\ttotal: 160ms\tremaining: 593ms\n",
      "61:\tlearn: 0.2113481\ttotal: 163ms\tremaining: 590ms\n",
      "62:\tlearn: 0.2103697\ttotal: 165ms\tremaining: 588ms\n",
      "63:\tlearn: 0.2087054\ttotal: 168ms\tremaining: 586ms\n",
      "64:\tlearn: 0.2076800\ttotal: 171ms\tremaining: 584ms\n",
      "65:\tlearn: 0.2068297\ttotal: 174ms\tremaining: 583ms\n",
      "66:\tlearn: 0.2057644\ttotal: 177ms\tremaining: 583ms\n",
      "67:\tlearn: 0.2045706\ttotal: 181ms\tremaining: 582ms\n",
      "68:\tlearn: 0.2034623\ttotal: 184ms\tremaining: 580ms\n",
      "69:\tlearn: 0.2018814\ttotal: 186ms\tremaining: 578ms\n",
      "70:\tlearn: 0.2014882\ttotal: 189ms\tremaining: 575ms\n",
      "71:\tlearn: 0.1998999\ttotal: 192ms\tremaining: 573ms\n",
      "72:\tlearn: 0.1988350\ttotal: 195ms\tremaining: 570ms\n",
      "73:\tlearn: 0.1979944\ttotal: 198ms\tremaining: 569ms\n",
      "74:\tlearn: 0.1962971\ttotal: 201ms\tremaining: 568ms\n",
      "75:\tlearn: 0.1954607\ttotal: 204ms\tremaining: 566ms\n",
      "76:\tlearn: 0.1933351\ttotal: 206ms\tremaining: 563ms\n",
      "77:\tlearn: 0.1923867\ttotal: 209ms\tremaining: 561ms\n",
      "78:\tlearn: 0.1912250\ttotal: 212ms\tremaining: 558ms\n",
      "79:\tlearn: 0.1896649\ttotal: 215ms\tremaining: 557ms\n",
      "80:\tlearn: 0.1894756\ttotal: 218ms\tremaining: 554ms\n",
      "81:\tlearn: 0.1875634\ttotal: 221ms\tremaining: 552ms\n",
      "82:\tlearn: 0.1870759\ttotal: 224ms\tremaining: 550ms\n",
      "83:\tlearn: 0.1866975\ttotal: 226ms\tremaining: 547ms\n",
      "84:\tlearn: 0.1849924\ttotal: 229ms\tremaining: 544ms\n",
      "85:\tlearn: 0.1835178\ttotal: 231ms\tremaining: 540ms\n",
      "86:\tlearn: 0.1820375\ttotal: 234ms\tremaining: 537ms\n",
      "87:\tlearn: 0.1805329\ttotal: 236ms\tremaining: 534ms\n",
      "88:\tlearn: 0.1793653\ttotal: 239ms\tremaining: 532ms\n",
      "89:\tlearn: 0.1782791\ttotal: 242ms\tremaining: 530ms\n",
      "90:\tlearn: 0.1772536\ttotal: 245ms\tremaining: 527ms\n",
      "91:\tlearn: 0.1755035\ttotal: 247ms\tremaining: 524ms\n",
      "92:\tlearn: 0.1741832\ttotal: 250ms\tremaining: 521ms\n",
      "93:\tlearn: 0.1737410\ttotal: 252ms\tremaining: 518ms\n",
      "94:\tlearn: 0.1724980\ttotal: 255ms\tremaining: 516ms\n",
      "95:\tlearn: 0.1714629\ttotal: 258ms\tremaining: 513ms\n",
      "96:\tlearn: 0.1709036\ttotal: 260ms\tremaining: 510ms\n",
      "97:\tlearn: 0.1696864\ttotal: 262ms\tremaining: 506ms\n",
      "98:\tlearn: 0.1682879\ttotal: 265ms\tremaining: 503ms\n",
      "99:\tlearn: 0.1678929\ttotal: 268ms\tremaining: 501ms\n",
      "100:\tlearn: 0.1672494\ttotal: 270ms\tremaining: 498ms\n",
      "101:\tlearn: 0.1671182\ttotal: 272ms\tremaining: 494ms\n",
      "102:\tlearn: 0.1659291\ttotal: 275ms\tremaining: 491ms\n",
      "103:\tlearn: 0.1652135\ttotal: 277ms\tremaining: 487ms\n",
      "104:\tlearn: 0.1640698\ttotal: 279ms\tremaining: 484ms\n",
      "105:\tlearn: 0.1633827\ttotal: 282ms\tremaining: 481ms\n",
      "106:\tlearn: 0.1622251\ttotal: 284ms\tremaining: 478ms\n",
      "107:\tlearn: 0.1611506\ttotal: 286ms\tremaining: 474ms\n",
      "108:\tlearn: 0.1601128\ttotal: 288ms\tremaining: 471ms\n",
      "109:\tlearn: 0.1589120\ttotal: 291ms\tremaining: 468ms\n",
      "110:\tlearn: 0.1578411\ttotal: 293ms\tremaining: 464ms\n",
      "111:\tlearn: 0.1568317\ttotal: 295ms\tremaining: 461ms\n",
      "112:\tlearn: 0.1559201\ttotal: 297ms\tremaining: 458ms\n",
      "113:\tlearn: 0.1547717\ttotal: 300ms\tremaining: 455ms\n",
      "114:\tlearn: 0.1541746\ttotal: 302ms\tremaining: 452ms\n",
      "115:\tlearn: 0.1527936\ttotal: 305ms\tremaining: 449ms\n",
      "116:\tlearn: 0.1520728\ttotal: 307ms\tremaining: 446ms\n",
      "117:\tlearn: 0.1512173\ttotal: 309ms\tremaining: 442ms\n",
      "118:\tlearn: 0.1504928\ttotal: 311ms\tremaining: 439ms\n",
      "119:\tlearn: 0.1497270\ttotal: 314ms\tremaining: 437ms\n",
      "120:\tlearn: 0.1496262\ttotal: 317ms\tremaining: 434ms\n",
      "121:\tlearn: 0.1490293\ttotal: 319ms\tremaining: 431ms\n",
      "122:\tlearn: 0.1476471\ttotal: 321ms\tremaining: 428ms\n",
      "123:\tlearn: 0.1465316\ttotal: 323ms\tremaining: 424ms\n",
      "124:\tlearn: 0.1460584\ttotal: 325ms\tremaining: 421ms\n",
      "125:\tlearn: 0.1452377\ttotal: 327ms\tremaining: 418ms\n",
      "126:\tlearn: 0.1444283\ttotal: 330ms\tremaining: 415ms\n",
      "127:\tlearn: 0.1436195\ttotal: 332ms\tremaining: 412ms\n",
      "128:\tlearn: 0.1429673\ttotal: 334ms\tremaining: 410ms\n",
      "129:\tlearn: 0.1423246\ttotal: 337ms\tremaining: 407ms\n",
      "130:\tlearn: 0.1417824\ttotal: 339ms\tremaining: 404ms\n",
      "131:\tlearn: 0.1405405\ttotal: 341ms\tremaining: 401ms\n",
      "132:\tlearn: 0.1396174\ttotal: 344ms\tremaining: 398ms\n",
      "133:\tlearn: 0.1391758\ttotal: 347ms\tremaining: 396ms\n",
      "134:\tlearn: 0.1384215\ttotal: 349ms\tremaining: 393ms\n",
      "135:\tlearn: 0.1379100\ttotal: 353ms\tremaining: 392ms\n",
      "136:\tlearn: 0.1367302\ttotal: 355ms\tremaining: 389ms\n",
      "137:\tlearn: 0.1363977\ttotal: 358ms\tremaining: 386ms\n",
      "138:\tlearn: 0.1356824\ttotal: 360ms\tremaining: 384ms\n",
      "139:\tlearn: 0.1344832\ttotal: 363ms\tremaining: 381ms\n",
      "140:\tlearn: 0.1335485\ttotal: 365ms\tremaining: 378ms\n",
      "141:\tlearn: 0.1329128\ttotal: 367ms\tremaining: 375ms\n",
      "142:\tlearn: 0.1315831\ttotal: 370ms\tremaining: 372ms\n",
      "143:\tlearn: 0.1307571\ttotal: 372ms\tremaining: 369ms\n",
      "144:\tlearn: 0.1303417\ttotal: 374ms\tremaining: 366ms\n",
      "145:\tlearn: 0.1300640\ttotal: 376ms\tremaining: 364ms\n",
      "146:\tlearn: 0.1287115\ttotal: 379ms\tremaining: 361ms\n",
      "147:\tlearn: 0.1280405\ttotal: 381ms\tremaining: 358ms\n",
      "148:\tlearn: 0.1275269\ttotal: 383ms\tremaining: 355ms\n",
      "149:\tlearn: 0.1265636\ttotal: 385ms\tremaining: 352ms\n",
      "150:\tlearn: 0.1262499\ttotal: 387ms\tremaining: 348ms\n",
      "151:\tlearn: 0.1260889\ttotal: 389ms\tremaining: 345ms\n",
      "152:\tlearn: 0.1258271\ttotal: 391ms\tremaining: 343ms\n",
      "153:\tlearn: 0.1255824\ttotal: 394ms\tremaining: 341ms\n",
      "154:\tlearn: 0.1246892\ttotal: 397ms\tremaining: 338ms\n",
      "155:\tlearn: 0.1235975\ttotal: 399ms\tremaining: 335ms\n",
      "156:\tlearn: 0.1230796\ttotal: 401ms\tremaining: 332ms\n",
      "157:\tlearn: 0.1222051\ttotal: 403ms\tremaining: 329ms\n",
      "158:\tlearn: 0.1215111\ttotal: 406ms\tremaining: 326ms\n",
      "159:\tlearn: 0.1214570\ttotal: 408ms\tremaining: 324ms\n",
      "160:\tlearn: 0.1207790\ttotal: 410ms\tremaining: 321ms\n",
      "161:\tlearn: 0.1204429\ttotal: 413ms\tremaining: 318ms\n",
      "162:\tlearn: 0.1194232\ttotal: 415ms\tremaining: 316ms\n",
      "163:\tlearn: 0.1186790\ttotal: 417ms\tremaining: 313ms\n",
      "164:\tlearn: 0.1182837\ttotal: 419ms\tremaining: 310ms\n",
      "165:\tlearn: 0.1176212\ttotal: 421ms\tremaining: 307ms\n",
      "166:\tlearn: 0.1171264\ttotal: 424ms\tremaining: 305ms\n",
      "167:\tlearn: 0.1165467\ttotal: 426ms\tremaining: 302ms\n",
      "168:\tlearn: 0.1160610\ttotal: 429ms\tremaining: 299ms\n",
      "169:\tlearn: 0.1153664\ttotal: 431ms\tremaining: 296ms\n",
      "170:\tlearn: 0.1143325\ttotal: 433ms\tremaining: 294ms\n",
      "171:\tlearn: 0.1134993\ttotal: 435ms\tremaining: 291ms\n",
      "172:\tlearn: 0.1127340\ttotal: 437ms\tremaining: 288ms\n",
      "173:\tlearn: 0.1118392\ttotal: 439ms\tremaining: 285ms\n",
      "174:\tlearn: 0.1113536\ttotal: 441ms\tremaining: 282ms\n",
      "175:\tlearn: 0.1110929\ttotal: 444ms\tremaining: 280ms\n",
      "176:\tlearn: 0.1107100\ttotal: 446ms\tremaining: 277ms\n",
      "177:\tlearn: 0.1102136\ttotal: 448ms\tremaining: 274ms\n",
      "178:\tlearn: 0.1100905\ttotal: 450ms\tremaining: 272ms\n",
      "179:\tlearn: 0.1098866\ttotal: 452ms\tremaining: 269ms\n",
      "180:\tlearn: 0.1096229\ttotal: 454ms\tremaining: 266ms\n",
      "181:\tlearn: 0.1090678\ttotal: 457ms\tremaining: 263ms\n",
      "182:\tlearn: 0.1083435\ttotal: 459ms\tremaining: 261ms\n",
      "183:\tlearn: 0.1078559\ttotal: 461ms\tremaining: 258ms\n",
      "184:\tlearn: 0.1069679\ttotal: 463ms\tremaining: 255ms\n",
      "185:\tlearn: 0.1063216\ttotal: 465ms\tremaining: 253ms\n",
      "186:\tlearn: 0.1053362\ttotal: 467ms\tremaining: 250ms\n",
      "187:\tlearn: 0.1051730\ttotal: 469ms\tremaining: 247ms\n",
      "188:\tlearn: 0.1048917\ttotal: 471ms\tremaining: 244ms\n",
      "189:\tlearn: 0.1044562\ttotal: 474ms\tremaining: 242ms\n",
      "190:\tlearn: 0.1040561\ttotal: 476ms\tremaining: 239ms\n",
      "191:\tlearn: 0.1039411\ttotal: 479ms\tremaining: 237ms\n",
      "192:\tlearn: 0.1034050\ttotal: 481ms\tremaining: 234ms\n",
      "193:\tlearn: 0.1027213\ttotal: 483ms\tremaining: 232ms\n",
      "194:\tlearn: 0.1024631\ttotal: 486ms\tremaining: 229ms\n",
      "195:\tlearn: 0.1020975\ttotal: 488ms\tremaining: 227ms\n",
      "196:\tlearn: 0.1018831\ttotal: 490ms\tremaining: 224ms\n",
      "197:\tlearn: 0.1013845\ttotal: 492ms\tremaining: 221ms\n",
      "198:\tlearn: 0.1010333\ttotal: 494ms\tremaining: 219ms\n",
      "199:\tlearn: 0.1005882\ttotal: 496ms\tremaining: 216ms\n",
      "200:\tlearn: 0.1005148\ttotal: 499ms\tremaining: 213ms\n",
      "201:\tlearn: 0.0997074\ttotal: 501ms\tremaining: 211ms\n",
      "202:\tlearn: 0.0990135\ttotal: 503ms\tremaining: 208ms\n",
      "203:\tlearn: 0.0984070\ttotal: 506ms\tremaining: 206ms\n",
      "204:\tlearn: 0.0979235\ttotal: 508ms\tremaining: 203ms\n",
      "205:\tlearn: 0.0975020\ttotal: 511ms\tremaining: 201ms\n",
      "206:\tlearn: 0.0969513\ttotal: 513ms\tremaining: 198ms\n",
      "207:\tlearn: 0.0967075\ttotal: 515ms\tremaining: 196ms\n",
      "208:\tlearn: 0.0962438\ttotal: 517ms\tremaining: 193ms\n",
      "209:\tlearn: 0.0957543\ttotal: 519ms\tremaining: 190ms\n",
      "210:\tlearn: 0.0953530\ttotal: 522ms\tremaining: 188ms\n",
      "211:\tlearn: 0.0946990\ttotal: 524ms\tremaining: 186ms\n",
      "212:\tlearn: 0.0945299\ttotal: 527ms\tremaining: 183ms\n",
      "213:\tlearn: 0.0944499\ttotal: 530ms\tremaining: 181ms\n",
      "214:\tlearn: 0.0942041\ttotal: 532ms\tremaining: 178ms\n",
      "215:\tlearn: 0.0933668\ttotal: 535ms\tremaining: 176ms\n",
      "216:\tlearn: 0.0929984\ttotal: 537ms\tremaining: 173ms\n",
      "217:\tlearn: 0.0926656\ttotal: 540ms\tremaining: 171ms\n",
      "218:\tlearn: 0.0919911\ttotal: 542ms\tremaining: 168ms\n",
      "219:\tlearn: 0.0916887\ttotal: 544ms\tremaining: 166ms\n",
      "220:\tlearn: 0.0913128\ttotal: 547ms\tremaining: 163ms\n",
      "221:\tlearn: 0.0912106\ttotal: 549ms\tremaining: 161ms\n",
      "222:\tlearn: 0.0904133\ttotal: 551ms\tremaining: 158ms\n",
      "223:\tlearn: 0.0902843\ttotal: 554ms\tremaining: 156ms\n",
      "224:\tlearn: 0.0896972\ttotal: 556ms\tremaining: 153ms\n",
      "225:\tlearn: 0.0891414\ttotal: 559ms\tremaining: 151ms\n",
      "226:\tlearn: 0.0886349\ttotal: 561ms\tremaining: 148ms\n",
      "227:\tlearn: 0.0883427\ttotal: 563ms\tremaining: 146ms\n",
      "228:\tlearn: 0.0881270\ttotal: 565ms\tremaining: 143ms\n",
      "229:\tlearn: 0.0873929\ttotal: 567ms\tremaining: 141ms\n",
      "230:\tlearn: 0.0867886\ttotal: 570ms\tremaining: 138ms\n",
      "231:\tlearn: 0.0865796\ttotal: 572ms\tremaining: 136ms\n",
      "232:\tlearn: 0.0861856\ttotal: 574ms\tremaining: 133ms\n",
      "233:\tlearn: 0.0860777\ttotal: 576ms\tremaining: 131ms\n",
      "234:\tlearn: 0.0856380\ttotal: 578ms\tremaining: 128ms\n",
      "235:\tlearn: 0.0851278\ttotal: 580ms\tremaining: 125ms\n",
      "236:\tlearn: 0.0845420\ttotal: 582ms\tremaining: 123ms\n",
      "237:\tlearn: 0.0840086\ttotal: 585ms\tremaining: 120ms\n",
      "238:\tlearn: 0.0836783\ttotal: 588ms\tremaining: 118ms\n",
      "239:\tlearn: 0.0833016\ttotal: 590ms\tremaining: 116ms\n",
      "240:\tlearn: 0.0827684\ttotal: 592ms\tremaining: 113ms\n",
      "241:\tlearn: 0.0822957\ttotal: 594ms\tremaining: 110ms\n",
      "242:\tlearn: 0.0819267\ttotal: 597ms\tremaining: 108ms\n",
      "243:\tlearn: 0.0815895\ttotal: 599ms\tremaining: 106ms\n",
      "244:\tlearn: 0.0810677\ttotal: 602ms\tremaining: 103ms\n",
      "245:\tlearn: 0.0805466\ttotal: 604ms\tremaining: 101ms\n",
      "246:\tlearn: 0.0803642\ttotal: 606ms\tremaining: 98.2ms\n",
      "247:\tlearn: 0.0800870\ttotal: 609ms\tremaining: 95.7ms\n",
      "248:\tlearn: 0.0794893\ttotal: 611ms\tremaining: 93.2ms\n",
      "249:\tlearn: 0.0792471\ttotal: 613ms\tremaining: 90.7ms\n",
      "250:\tlearn: 0.0792192\ttotal: 615ms\tremaining: 88.2ms\n",
      "251:\tlearn: 0.0787408\ttotal: 618ms\tremaining: 85.8ms\n",
      "252:\tlearn: 0.0785494\ttotal: 620ms\tremaining: 83.3ms\n",
      "253:\tlearn: 0.0783914\ttotal: 623ms\tremaining: 80.9ms\n",
      "254:\tlearn: 0.0779681\ttotal: 625ms\tremaining: 78.5ms\n",
      "255:\tlearn: 0.0776613\ttotal: 629ms\tremaining: 76.1ms\n",
      "256:\tlearn: 0.0773809\ttotal: 631ms\tremaining: 73.6ms\n",
      "257:\tlearn: 0.0771712\ttotal: 633ms\tremaining: 71.2ms\n",
      "258:\tlearn: 0.0768738\ttotal: 636ms\tremaining: 68.7ms\n",
      "259:\tlearn: 0.0762334\ttotal: 638ms\tremaining: 66.2ms\n",
      "260:\tlearn: 0.0759132\ttotal: 640ms\tremaining: 63.8ms\n",
      "261:\tlearn: 0.0753329\ttotal: 642ms\tremaining: 61.3ms\n",
      "262:\tlearn: 0.0751849\ttotal: 644ms\tremaining: 58.8ms\n",
      "263:\tlearn: 0.0749642\ttotal: 646ms\tremaining: 56.3ms\n",
      "264:\tlearn: 0.0748469\ttotal: 649ms\tremaining: 53.8ms\n",
      "265:\tlearn: 0.0744926\ttotal: 651ms\tremaining: 51.4ms\n",
      "266:\tlearn: 0.0741167\ttotal: 653ms\tremaining: 48.9ms\n",
      "267:\tlearn: 0.0735633\ttotal: 655ms\tremaining: 46.4ms\n",
      "268:\tlearn: 0.0733733\ttotal: 657ms\tremaining: 43.9ms\n",
      "269:\tlearn: 0.0729637\ttotal: 659ms\tremaining: 41.5ms\n",
      "270:\tlearn: 0.0725461\ttotal: 661ms\tremaining: 39ms\n",
      "271:\tlearn: 0.0719559\ttotal: 662ms\tremaining: 36.5ms\n",
      "272:\tlearn: 0.0716603\ttotal: 664ms\tremaining: 34.1ms\n",
      "273:\tlearn: 0.0714195\ttotal: 667ms\tremaining: 31.6ms\n",
      "274:\tlearn: 0.0709534\ttotal: 669ms\tremaining: 29.2ms\n",
      "275:\tlearn: 0.0705621\ttotal: 671ms\tremaining: 26.7ms\n",
      "276:\tlearn: 0.0701189\ttotal: 673ms\tremaining: 24.3ms\n",
      "277:\tlearn: 0.0696632\ttotal: 675ms\tremaining: 21.9ms\n",
      "278:\tlearn: 0.0693334\ttotal: 677ms\tremaining: 19.4ms\n",
      "279:\tlearn: 0.0689864\ttotal: 680ms\tremaining: 17ms\n",
      "280:\tlearn: 0.0684884\ttotal: 682ms\tremaining: 14.6ms\n",
      "281:\tlearn: 0.0681858\ttotal: 685ms\tremaining: 12.1ms\n",
      "282:\tlearn: 0.0681504\ttotal: 687ms\tremaining: 9.71ms\n",
      "283:\tlearn: 0.0679930\ttotal: 689ms\tremaining: 7.28ms\n",
      "284:\tlearn: 0.0675748\ttotal: 692ms\tremaining: 4.85ms\n",
      "285:\tlearn: 0.0671349\ttotal: 694ms\tremaining: 2.42ms\n",
      "286:\tlearn: 0.0664195\ttotal: 696ms\tremaining: 0us\n",
      "Train Accuracy: 0.9897, Precision: 0.9897, Recall: 0.9897, F1 Score: 0.9897\n",
      "Validation Accuracy: 0.8815, Precision: 0.8822, Recall: 0.8815, F1 Score: 0.8817\n",
      "Test Accuracy: 0.8632, Precision: 0.8634, Recall: 0.8632, F1 Score: 0.8622\n"
     ]
    }
   ],
   "source": [
    "best_classifer = train_best_model(X_train_koi,y_train_koi,X_val_koi,y_val_koi,X_test_koi,y_test_koi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48d407",
   "metadata": {},
   "source": [
    "## 6. Output the file for web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a9d8fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model file\n",
    "best_classifer.save_model(\"best_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "48004df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names\n",
    "feature_names = list(X_train_koi.columns)\n",
    "with open(\"features.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"features\": feature_names}, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizer\n",
    "std_params = {\"features\": feature_names,\n",
    "              \"mean\":  np.asarray(scaler_koi.mean_).tolist(),\n",
    "              \"scale\": np.asarray(scaler_koi.scale_).tolist()}\n",
    "json.dump(std_params, open(\"standardizer.json\",\"w\"), indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
